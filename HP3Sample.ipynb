{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HP3Sample.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumandutta8877/HP3Lab/blob/master/HP3Sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gkHEqUogBZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "792c9963-d1ae-43da-f695-01a1fad9d88d"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKqBLCsvaRUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9803d98f-2c2f-4cf9-e260-816f0d6fad69"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-9t7tcv72\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-9t7tcv72\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=fcd6bdd34306e244bf882f7e998d00341e14747b6c4deca9e55ebe56a26d5bdc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a76kxmrv/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCiN6AumaZ3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b9cc2f-7daa-4b77-a1b9-155a8ab7822b"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3FV18gqaiNl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb185f69-9f1e-4361-a7c7-ff5599750959"
      },
      "source": [
        "%%cuda --name helloCUDA.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void vectorAdd(const float *A, const float *B, float *C, int numElements)\n",
        "{\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    if (i < numElements)\n",
        "    {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "    // Error code to check return values for CUDA calls\n",
        "    cudaError_t err = cudaSuccess;\n",
        "\n",
        "    // Print the vector length to be used, and compute its size\n",
        "    int numElements = 0;\n",
        "    scanf(\"%d\",&numElements);\n",
        "    \n",
        "    size_t size = numElements * sizeof(float);\n",
        "    printf(\"[Vector addition of %d elements]\\n\", numElements);\n",
        "\n",
        "    // Allocate the host input vector A\n",
        "    float *h_A = (float *)malloc(size);\n",
        "\n",
        "    // Allocate the host input vector B\n",
        "    float *h_B = (float *)malloc(size);\n",
        "\n",
        "    // Allocate the host output vector C\n",
        "    float *h_C = (float *)malloc(size);\n",
        "\n",
        "    // Verify that allocations succeeded\n",
        "    if (h_A == NULL || h_B == NULL || h_C == NULL)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate host vectors!\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Initialize the host input vectors\n",
        "    for (int i = 0; i < numElements; ++i)\n",
        "    {\n",
        "        h_A[i] = rand()/(float)RAND_MAX;\n",
        "        h_B[i] = rand()/(float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Allocate the device input vector A\n",
        "    float *d_A = NULL;\n",
        "    err = cudaMalloc((void **)&d_A, size);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Allocate the device input vector B\n",
        "    float *d_B = NULL;\n",
        "    err = cudaMalloc((void **)&d_B, size);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Allocate the device output vector C\n",
        "    float *d_C = NULL;\n",
        "    err = cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Copy the host input vectors A and B in host memory to the device input vectors in\n",
        "    // device memory\n",
        "    printf(\"Copy input data from the host memory to the CUDA device\\n\");\n",
        "    err = cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to copy vector A from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    err = cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to copy vector B from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Launch the Vector Add CUDA Kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid =(numElements + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", blocksPerGrid, threadsPerBlock);\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, numElements);\n",
        "    err = cudaGetLastError();\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to launch vectorAdd kernel (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Copy the device result vector in device memory to the host result vector\n",
        "    // in host memory.\n",
        "    printf(\"Copy output data from the CUDA device to the host memory\\n\");\n",
        "    err = cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to copy vector C from device to host (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Verify that the result vector is correct\n",
        "    for (int i = 0; i < numElements; ++i)\n",
        "    {\n",
        "        if (fabs(h_A[i] + h_B[i] - h_C[i]) > 1e-5)\n",
        "        {\n",
        "            fprintf(stderr, \"Result verification failed at element %d!\\n\", i);\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    printf(\"Test PASSED\\n\");\n",
        "\n",
        "    // Free device global memory\n",
        "    err = cudaFree(d_A);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    err = cudaFree(d_B);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    err = cudaFree(d_C);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    // Reset the device and exit\n",
        "    // cudaDeviceReset causes the driver to clean up all state. While\n",
        "    // not mandatory in normal operation, it is good practice.  It is also\n",
        "    // needed to ensure correct operation when the application is being\n",
        "    // profiled. Calling cudaDeviceReset causes all profile data to be\n",
        "    // flushed before the application exits\n",
        "    err = cudaDeviceReset();\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to deinitialize the device! error=%s\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    printf(\"Done\\n\");\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/helloCUDA.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ncVM7H-n85I"
      },
      "source": [
        "!nvcc /content/src/helloCUDA.cu -o /content/src/helloCUDA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXq-m0VsoOCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8d1fd5-4169-4223-f4c6-5cc948203f6c"
      },
      "source": [
        "!/content/src/helloCUDA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "[Vector addition of 50000 elements]\n",
            "Copy input data from the host memory to the CUDA device\n",
            "CUDA kernel launch with 196 blocks of 256 threads\n",
            "Copy output data from the CUDA device to the host memory\n",
            "Test PASSED\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xsbqWJdJYb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6a93fe40-651c-4608-e59e-1df2566ec9e1"
      },
      "source": [
        "%%cuda --name helloCUDA_input.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void vectorAdd(const float *A, const float *B, float *C, int numElements)\n",
        "{\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    if (i < numElements)\n",
        "    {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "    // Error code to check return values for CUDA calls\n",
        "    cudaError_t err = cudaSuccess;\n",
        "\n",
        "    // Print the vector length to be used, and compute its size\n",
        "    int numElements = 0;\n",
        "    int t;\n",
        "    scanf(\"%d\",&t);\n",
        "    while(t--)\n",
        "    {\n",
        "        scanf(\"%d\",&numElements);\n",
        "\n",
        "        size_t size = numElements * sizeof(float);\n",
        "        printf(\"[Vector addition of %d elements]\\n\", numElements);\n",
        "\n",
        "        // Allocate the host input vector A\n",
        "        float *h_A = (float *)malloc(size);\n",
        "\n",
        "        // Allocate the host input vector B\n",
        "        float *h_B = (float *)malloc(size);\n",
        "\n",
        "        // Allocate the host output vector C\n",
        "        float *h_C = (float *)malloc(size);\n",
        "\n",
        "        // Verify that allocations succeeded\n",
        "        if (h_A == NULL || h_B == NULL || h_C == NULL)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to allocate host vectors!\\n\");\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Initialize the host input vectors\n",
        "        for (int i = 0; i < numElements; ++i)\n",
        "        {\n",
        "            h_A[i] = rand()/(float)RAND_MAX;\n",
        "            h_B[i] = rand()/(float)RAND_MAX;\n",
        "        }\n",
        "\n",
        "        // Allocate the device input vector A\n",
        "        float *d_A = NULL;\n",
        "        err = cudaMalloc((void **)&d_A, size);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to allocate device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Allocate the device input vector B\n",
        "        float *d_B = NULL;\n",
        "        err = cudaMalloc((void **)&d_B, size);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to allocate device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Allocate the device output vector C\n",
        "        float *d_C = NULL;\n",
        "        err = cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to allocate device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Copy the host input vectors A and B in host memory to the device input vectors in\n",
        "        // device memory\n",
        "        printf(\"Copy input data from the host memory to the CUDA device\\n\");\n",
        "        err = cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to copy vector A from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        err = cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to copy vector B from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Launch the Vector Add CUDA Kernel\n",
        "        int threadsPerBlock = 256;\n",
        "        int blocksPerGrid =(numElements + threadsPerBlock - 1) / threadsPerBlock;\n",
        "        printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", blocksPerGrid, threadsPerBlock);\n",
        "        vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, numElements);\n",
        "        err = cudaGetLastError();\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to launch vectorAdd kernel (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Copy the device result vector in device memory to the host result vector\n",
        "        // in host memory.\n",
        "        printf(\"Copy output data from the CUDA device to the host memory\\n\");\n",
        "        err = cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to copy vector C from device to host (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Verify that the result vector is correct\n",
        "        for (int i = 0; i < numElements; ++i)\n",
        "        {\n",
        "            if (fabs(h_A[i] + h_B[i] - h_C[i]) > 1e-5)\n",
        "            {\n",
        "                fprintf(stderr, \"Result verification failed at element %d!\\n\", i);\n",
        "                exit(EXIT_FAILURE);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        printf(\"Test PASSED\\n\");\n",
        "\n",
        "        // Free device global memory\n",
        "        err = cudaFree(d_A);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to free device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        err = cudaFree(d_B);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to free device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        err = cudaFree(d_C);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to free device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Free host memory\n",
        "        free(h_A);\n",
        "        free(h_B);\n",
        "        free(h_C);\n",
        "\n",
        "        // Reset the device and exit\n",
        "        // cudaDeviceReset causes the driver to clean up all state. While\n",
        "        // not mandatory in normal operation, it is good practice.  It is also\n",
        "        // needed to ensure correct operation when the application is being\n",
        "        // profiled. Calling cudaDeviceReset causes all profile data to be\n",
        "        // flushed before the application exits\n",
        "        err = cudaDeviceReset();\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to deinitialize the device! error=%s\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        printf(\"Done\\n\");\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/helloCUDA_input.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbjmHpBrJfQf"
      },
      "source": [
        "!nvcc /content/src/helloCUDA_input.cu -o helloCUDA_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQTA2udPJvPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a2767c-f5f7-46c7-83dd-2138d637ad35"
      },
      "source": [
        "!/content/helloCUDA_input < /content/input.txt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Vector addition of 10000 elements]\n",
            "Copy input data from the host memory to the CUDA device\n",
            "CUDA kernel launch with 40 blocks of 256 threads\n",
            "Copy output data from the CUDA device to the host memory\n",
            "Test PASSED\n",
            "Done\n",
            "[Vector addition of 20000 elements]\n",
            "Copy input data from the host memory to the CUDA device\n",
            "CUDA kernel launch with 79 blocks of 256 threads\n",
            "Copy output data from the CUDA device to the host memory\n",
            "Test PASSED\n",
            "Done\n",
            "[Vector addition of 30000 elements]\n",
            "Copy input data from the host memory to the CUDA device\n",
            "CUDA kernel launch with 118 blocks of 256 threads\n",
            "Copy output data from the CUDA device to the host memory\n",
            "Test PASSED\n",
            "Done\n",
            "[Vector addition of 40000 elements]\n",
            "Copy input data from the host memory to the CUDA device\n",
            "CUDA kernel launch with 157 blocks of 256 threads\n",
            "Copy output data from the CUDA device to the host memory\n",
            "Test PASSED\n",
            "Done\n",
            "[Vector addition of 50000 elements]\n",
            "Copy input data from the host memory to the CUDA device\n",
            "CUDA kernel launch with 196 blocks of 256 threads\n",
            "Copy output data from the CUDA device to the host memory\n",
            "Test PASSED\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqBdBtUML7xk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b963d18-10e1-4592-e02e-34b5a95a004e"
      },
      "source": [
        "%%cuda --name helloCUDA_input_test.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void vectorAdd(const float *A, const float *B, float *C, int numElements)\n",
        "{\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    if (i < numElements)\n",
        "    {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "    // Error code to check return values for CUDA calls\n",
        "    cudaError_t err = cudaSuccess;\n",
        "\n",
        "    // Print the vector length to be used, and compute its size\n",
        "    int numElements = 0;\n",
        "    int t;\n",
        "    scanf(\"%d\",&t);\n",
        "    while(t--)\n",
        "    {\n",
        "        scanf(\"%d\",&numElements);\n",
        "\n",
        "        size_t size = numElements * sizeof(float);\n",
        "        //printf(\"[Vector addition of %d elements]\\n\", numElements);\n",
        "\n",
        "        // Allocate the host input vector A\n",
        "        float *h_A = (float *)malloc(size);\n",
        "\n",
        "        // Allocate the host input vector B\n",
        "        float *h_B = (float *)malloc(size);\n",
        "\n",
        "        // Allocate the host output vector C\n",
        "        float *h_C = (float *)malloc(size);\n",
        "\n",
        "        // Verify that allocations succeeded\n",
        "        if (h_A == NULL || h_B == NULL || h_C == NULL)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to allocate host vectors!\\n\");\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Initialize the host input vectors\n",
        "        for (int i = 0; i < numElements; ++i)\n",
        "        {\n",
        "            scanf(\"%f\",&h_A[i]);\n",
        "         \n",
        "        }\n",
        "        for (int i = 0; i < numElements; ++i)\n",
        "        {\n",
        "         \n",
        "            scanf(\"%f\",&h_B[i]);\n",
        "        }\n",
        "\n",
        "        \n",
        "        // Allocate the device input vector A\n",
        "        float *d_A = NULL;\n",
        "        err = cudaMalloc((void **)&d_A, size);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to allocate device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Allocate the device input vector B\n",
        "        float *d_B = NULL;\n",
        "        err = cudaMalloc((void **)&d_B, size);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to allocate device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Allocate the device output vector C\n",
        "        float *d_C = NULL;\n",
        "        err = cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to allocate device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Copy the host input vectors A and B in host memory to the device input vectors in\n",
        "        // device memory\n",
        "       // printf(\"Copy input data from the host memory to the CUDA device\\n\");\n",
        "        err = cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to copy vector A from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        err = cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to copy vector B from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Launch the Vector Add CUDA Kernel\n",
        "        int threadsPerBlock = 256;\n",
        "        int blocksPerGrid =(numElements + threadsPerBlock - 1) / threadsPerBlock;\n",
        "        //printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", blocksPerGrid, threadsPerBlock);\n",
        "        vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, numElements);\n",
        "        err = cudaGetLastError();\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to launch vectorAdd kernel (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Copy the device result vector in device memory to the host result vector\n",
        "        // in host memory.\n",
        "       // printf(\"Copy output data from the CUDA device to the host memory\\n\");\n",
        "        err = cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to copy vector C from device to host (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        // Verify that the result vector is correct\n",
        "        for (int i = 0; i < numElements; ++i)\n",
        "        {\n",
        "            if (fabs(h_A[i] + h_B[i] - h_C[i]) > 1e-5)\n",
        "            {\n",
        "                fprintf(stderr, \"Result verification failed at element %d!\\n\", i);\n",
        "                exit(EXIT_FAILURE);\n",
        "            }\n",
        "        }\n",
        "\n",
        "       // printf(\"Test PASSED\\n\");\n",
        "\n",
        "        // Free device global memory\n",
        "        err = cudaFree(d_A);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to free device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        err = cudaFree(d_B);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to free device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "        err = cudaFree(d_C);\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to free device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "       \n",
        "\n",
        "        // Reset the device and exit\n",
        "        // cudaDeviceReset causes the driver to clean up all state. While\n",
        "        // not mandatory in normal operation, it is good practice.  It is also\n",
        "        // needed to ensure correct operation when the application is being\n",
        "        // profiled. Calling cudaDeviceReset causes all profile data to be\n",
        "        // flushed before the application exits\n",
        "        err = cudaDeviceReset();\n",
        "\n",
        "        if (err != cudaSuccess)\n",
        "        {\n",
        "            fprintf(stderr, \"Failed to deinitialize the device! error=%s\\n\", cudaGetErrorString(err));\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "        for (int i = 0; i < numElements; ++i)\n",
        "        {\n",
        "            printf(\"%.2f \",h_C[i]);\n",
        "        }       \n",
        "      // Free host memory\n",
        "        free(h_A);\n",
        "        free(h_B);\n",
        "        free(h_C);\n",
        "        printf(\"\\n\");\n",
        "        //printf(\"Done\\n\");\n",
        "    \n",
        "    }\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/helloCUDA_input_test.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qASaGRg4Npxa"
      },
      "source": [
        "!nvcc /content/src/helloCUDA_input_test.cu -o helloCUDA_input_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ8xPoKfOFBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b107356-2dfe-4ec5-b903-fe78e780adfc"
      },
      "source": [
        "!/content/helloCUDA_input_test < /content/input_example.txt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.23 1.58 1.11 1.11 0.83 1.11 0.87 1.87 1.36 0.75 0.26 0.94 0.56 0.24 1.22 1.35 0.91 1.16 1.46 1.06 1.30 1.29 0.63 1.73 1.02 0.62 0.85 1.24 0.08 0.52 1.21 1.75 0.81 1.14 1.18 0.57 1.37 1.65 1.02 0.99 0.86 1.32 1.16 1.12 1.04 1.55 1.52 1.36 1.21 1.59 0.70 1.87 1.03 1.07 0.90 1.10 0.68 0.47 0.98 1.08 0.23 1.26 1.92 1.06 1.12 0.52 0.82 0.88 0.92 0.91 1.02 0.57 0.42 1.53 1.63 1.40 0.22 0.60 0.27 1.28 1.33 0.21 1.20 1.02 1.05 0.94 0.92 0.77 0.55 1.73 0.91 1.03 0.79 1.29 1.29 1.46 1.38 0.79 1.76 1.70 1.72 1.88 1.17 0.99 0.97 0.90 0.86 1.02 0.56 0.70 0.87 1.48 0.83 0.83 1.06 1.39 1.19 0.43 0.94 1.06 1.16 0.78 0.89 0.66 1.11 1.31 0.53 1.24 1.06 0.94 1.60 0.91 0.62 1.14 0.78 0.47 1.17 0.96 1.07 0.52 0.98 1.16 0.63 1.88 1.46 0.81 1.15 1.86 1.06 1.34 1.20 1.78 1.08 0.43 1.35 1.31 0.79 0.86 0.87 1.09 1.56 0.40 0.62 0.50 1.25 1.53 1.66 0.83 1.05 0.87 0.22 0.76 0.65 0.42 1.36 0.85 1.42 0.65 1.51 0.73 0.99 1.22 0.57 1.37 1.32 1.04 0.42 1.55 0.40 1.59 0.50 1.70 0.68 0.96 0.48 0.96 0.94 0.10 1.24 1.13 0.71 1.11 0.96 1.19 0.65 1.14 1.22 1.06 0.17 1.09 0.71 1.12 1.24 1.15 0.70 1.04 1.47 0.53 0.81 0.78 1.50 0.60 0.75 0.62 0.68 0.57 0.76 1.05 0.91 1.47 1.50 1.01 0.66 1.37 1.26 0.92 1.08 1.48 0.18 0.75 0.81 1.27 0.01 0.57 1.52 0.52 1.55 0.96 1.08 0.66 1.51 1.09 1.10 1.42 1.67 1.16 1.48 1.04 1.74 1.40 1.66 1.26 1.46 1.40 1.57 0.86 0.64 1.67 1.53 1.02 1.25 0.69 0.61 1.22 1.35 0.60 0.56 1.19 1.09 0.55 0.66 0.74 1.38 1.03 1.48 0.13 1.24 0.44 1.55 1.20 1.29 1.90 1.67 0.87 0.70 1.42 1.85 0.64 1.55 1.16 1.72 0.73 1.11 0.81 0.84 1.57 0.82 0.98 0.57 1.24 1.28 0.62 0.80 0.36 0.93 1.37 1.82 0.62 1.29 1.61 0.45 1.25 1.65 0.75 1.07 1.49 1.64 0.46 0.37 0.81 0.36 0.96 0.28 1.11 1.02 0.68 0.89 0.73 1.15 0.76 0.46 1.56 1.36 0.56 0.86 1.03 1.54 0.39 1.57 1.38 1.21 1.05 1.00 0.64 0.26 0.38 0.65 1.84 0.99 0.73 0.76 1.06 1.75 1.11 0.96 0.89 0.56 1.28 0.73 0.71 1.33 0.71 1.03 0.97 0.94 0.87 1.45 0.99 1.38 0.51 0.58 1.50 1.35 1.70 0.70 0.06 0.50 1.00 1.33 0.55 0.67 0.96 0.32 1.32 1.05 1.04 1.24 0.79 1.32 1.66 0.89 1.05 0.51 0.91 1.03 1.11 0.86 1.83 1.03 0.89 0.97 0.73 0.46 0.80 0.99 0.79 1.20 1.25 0.89 0.55 0.61 0.61 0.74 0.66 0.59 0.86 1.47 1.78 0.11 0.71 1.04 0.99 1.34 0.95 1.40 1.14 1.16 0.48 1.20 1.68 1.68 1.35 1.14 1.08 0.70 1.36 0.28 0.98 1.58 0.85 0.42 0.99 0.75 0.49 1.61 0.73 1.72 0.43 1.20 1.10 1.30 1.64 0.80 1.21 1.53 0.36 1.05 0.54 0.82 0.75 1.20 0.71 1.56 0.77 0.66 0.67 1.33 1.55 0.93 0.51 0.83 0.43 1.23 0.68 0.99 0.47 0.90 1.10 1.34 0.22 1.74 0.97 1.20 1.21 1.30 1.60 0.60 0.99 0.99 0.88 1.10 1.18 0.55 0.46 1.13 0.89 0.57 0.94 0.39 0.90 1.87 0.80 0.54 1.29 1.47 0.53 0.53 1.57 0.98 0.96 0.71 0.99 1.72 1.05 0.07 1.80 0.46 0.40 1.40 0.53 0.87 1.44 0.76 1.47 1.03 0.86 1.29 1.02 1.78 1.11 1.02 1.79 0.51 0.48 0.89 0.79 1.07 1.16 1.23 1.58 1.07 1.01 1.29 0.36 1.09 0.92 0.39 1.59 0.90 0.82 1.08 1.55 0.83 0.99 0.33 1.31 1.01 1.77 1.35 0.36 0.61 1.55 0.99 0.90 1.19 0.67 1.31 1.42 0.92 1.18 0.97 0.66 0.82 0.26 0.56 0.60 0.91 0.15 1.28 0.77 0.76 1.74 0.66 1.22 0.55 1.82 0.91 0.49 0.91 0.89 1.39 1.62 1.62 1.19 0.84 1.38 1.39 0.68 1.27 0.62 1.31 1.35 0.92 0.94 0.61 1.29 1.31 0.30 1.71 0.85 0.44 0.14 1.35 0.89 1.73 1.45 0.96 0.24 1.64 0.70 1.01 1.24 1.91 1.27 1.02 0.15 0.34 0.31 1.13 1.30 0.70 0.88 0.55 1.52 1.32 0.44 0.23 0.64 0.22 1.76 1.03 0.70 1.21 1.05 1.20 0.20 1.10 1.56 1.21 0.84 1.32 0.85 0.97 0.69 0.41 0.43 0.37 1.80 1.16 0.92 1.19 1.27 1.19 0.93 0.91 0.92 0.05 0.78 1.27 0.21 0.91 1.10 0.79 0.86 0.74 1.30 0.87 0.21 1.39 1.46 0.93 1.52 1.16 0.99 0.76 1.10 0.84 0.96 0.09 1.56 0.58 0.76 0.43 1.51 1.12 1.12 1.36 1.02 0.93 0.94 1.20 0.38 1.22 1.66 1.15 1.14 1.10 1.17 0.88 0.35 1.65 1.05 1.12 1.52 0.09 0.75 1.49 1.33 1.46 1.03 0.23 0.33 0.07 0.87 1.18 0.95 0.71 0.84 1.09 0.87 0.84 0.47 1.76 1.04 0.81 0.83 1.24 1.37 0.66 0.26 1.48 0.68 1.22 1.00 0.90 1.50 1.48 1.07 0.78 1.47 1.19 0.63 1.46 0.74 1.25 0.97 1.22 0.90 1.18 1.77 0.75 0.82 0.23 1.48 1.01 0.58 1.23 1.62 1.21 0.81 1.37 0.18 1.42 1.05 0.96 0.69 1.07 0.94 1.40 1.30 1.33 0.60 0.09 0.25 0.59 0.77 1.83 0.55 1.01 0.86 1.41 0.67 1.06 1.77 1.01 0.88 0.96 0.91 1.71 0.36 0.21 0.27 1.06 1.31 1.41 1.04 1.71 1.28 1.32 0.24 1.13 0.68 1.61 1.14 1.75 0.62 1.62 1.01 1.71 0.76 1.48 0.93 0.51 0.97 1.28 1.16 0.32 1.50 0.42 1.25 1.13 1.13 0.77 1.44 0.46 1.59 0.99 1.14 1.75 1.34 0.30 0.43 1.33 0.56 0.57 0.92 0.68 1.45 1.19 0.92 0.08 0.59 1.02 1.57 1.84 1.80 0.40 0.78 0.17 0.49 1.15 1.44 0.45 1.27 1.78 1.29 1.67 0.92 1.63 1.47 1.38 1.60 1.50 1.53 1.72 0.41 1.42 0.69 0.74 0.51 1.14 0.37 0.70 0.52 1.75 0.78 1.26 0.92 0.76 0.43 0.46 1.35 0.68 0.75 0.99 0.93 1.07 0.95 1.57 1.10 1.45 0.45 1.27 1.46 0.81 0.52 1.71 0.13 0.90 0.81 1.15 0.04 1.04 1.00 1.45 0.92 0.97 1.61 0.74 1.27 0.96 1.81 1.65 0.06 0.83 1.46 0.63 1.20 0.49 0.28 1.29 0.84 0.57 1.50 1.51 0.84 1.56 1.14 1.59 0.78 1.09 0.40 0.74 1.40 0.79 0.15 0.87 0.34 0.43 0.73 1.62 1.42 1.22 1.40 0.77 1.23 0.41 1.58 0.23 1.37 0.66 1.10 1.50 0.97 1.29 0.88 0.28 1.09 0.86 0.32 0.66 1.48 0.18 1.21 1.05 1.43 1.09 1.24 0.97 1.52 0.92 1.18 0.69 1.71 0.76 1.16 0.58 0.48 0.71 1.18 \n",
            "0.27 0.48 1.14 0.94 0.93 1.36 0.86 1.05 0.80 1.08 0.79 0.97 0.89 0.14 1.14 1.37 0.93 0.76 1.55 0.17 1.17 1.34 1.07 1.56 0.15 1.43 0.89 1.32 0.85 1.38 0.78 0.41 1.57 0.78 0.89 0.62 0.47 1.07 1.33 0.42 1.28 1.42 1.24 0.95 1.20 1.10 1.07 1.69 1.70 0.78 0.40 0.64 1.34 1.43 0.35 1.14 0.69 0.81 0.31 1.03 0.09 0.49 1.64 0.81 1.64 0.92 0.98 0.92 1.28 0.98 1.18 1.28 0.70 0.80 0.85 1.51 0.96 1.10 1.18 0.94 0.49 0.87 0.42 0.77 1.14 0.33 0.88 1.18 0.69 0.59 0.80 1.48 0.10 1.36 1.48 1.11 1.15 1.42 0.78 1.27 0.95 1.23 1.20 1.40 0.39 1.42 1.09 0.94 1.46 0.46 1.59 0.89 1.56 1.32 0.50 1.25 1.18 0.28 0.90 1.27 1.67 1.48 0.58 0.93 0.71 0.98 0.97 1.04 1.18 0.87 0.94 1.13 1.61 1.50 1.09 0.81 0.46 0.51 0.70 1.09 0.85 1.72 1.93 1.35 1.11 0.78 1.35 1.17 0.32 1.48 1.45 1.17 0.57 0.96 1.12 0.69 1.12 0.78 1.17 1.15 1.36 1.34 0.85 0.67 1.17 0.58 1.44 1.53 0.43 1.28 1.55 0.52 0.39 0.71 0.44 0.84 0.80 1.51 1.68 0.82 1.34 1.48 1.16 0.80 0.50 0.14 1.07 0.72 0.97 1.01 0.29 1.20 1.04 0.74 0.90 1.57 0.97 1.03 1.06 0.72 0.91 0.61 1.53 1.43 0.75 0.91 1.31 1.12 0.82 1.05 0.41 0.96 1.65 0.50 0.80 1.27 1.08 1.68 1.21 1.10 1.56 0.99 1.12 1.20 0.95 1.65 0.86 0.73 0.59 1.23 1.45 0.09 1.38 1.13 0.89 1.54 1.24 1.31 1.64 1.29 0.75 0.95 1.55 0.13 0.93 0.52 0.86 0.90 1.39 0.83 1.28 0.73 0.91 0.88 0.54 1.15 1.11 1.90 0.80 1.79 1.39 1.11 1.92 0.50 1.06 0.59 1.71 0.86 0.36 1.18 0.92 1.18 1.45 0.69 1.11 0.97 0.77 0.76 1.10 1.00 0.58 0.50 0.92 0.92 1.11 1.17 1.44 1.05 1.43 1.12 1.21 1.05 0.18 0.67 1.06 1.43 0.26 0.94 1.30 1.44 0.97 0.43 0.96 1.29 1.24 1.95 0.50 1.42 0.80 0.96 0.76 0.51 1.32 1.18 0.32 1.02 1.24 1.70 0.97 0.60 0.40 0.65 0.53 1.57 1.17 0.19 0.92 0.94 1.16 1.86 0.76 0.78 1.35 1.19 0.47 0.53 1.33 0.76 1.25 1.19 0.86 1.34 1.08 1.03 0.41 1.73 0.78 0.15 1.98 0.45 1.13 0.31 1.14 0.31 0.41 0.80 1.88 1.06 0.44 1.20 0.96 1.01 0.42 0.87 0.51 0.85 1.29 1.10 0.24 0.83 0.91 0.93 0.79 1.73 1.06 1.07 0.85 0.77 1.25 0.67 0.97 0.40 1.70 0.70 1.91 0.60 1.15 0.61 0.51 1.16 1.27 1.60 0.33 0.38 1.02 1.34 0.58 1.25 1.25 1.21 1.46 0.99 1.34 0.56 0.93 0.42 0.97 0.32 0.40 0.88 1.77 0.41 0.96 0.62 0.61 1.38 0.65 0.69 0.96 0.84 0.97 1.09 0.29 0.23 1.11 1.11 1.31 1.22 1.19 0.49 0.67 0.87 0.25 1.31 0.82 1.08 1.42 0.73 0.58 1.40 1.05 0.58 1.04 1.65 0.64 1.01 1.02 0.64 1.46 0.45 0.11 1.07 1.71 0.25 0.77 1.98 1.15 1.20 0.34 1.41 0.98 1.29 1.32 0.26 0.89 1.05 1.25 0.54 0.93 1.24 1.43 1.51 1.77 0.77 0.55 1.10 0.61 1.54 0.33 1.70 0.51 1.23 0.87 1.72 0.55 0.48 1.19 1.57 0.69 1.08 1.52 0.78 1.57 1.05 1.12 1.11 1.50 1.39 1.12 1.15 0.07 0.66 0.62 1.22 1.58 1.56 0.48 0.22 1.65 0.93 1.02 0.39 1.38 0.89 0.89 1.18 0.68 1.22 1.07 0.63 0.74 0.74 1.52 1.24 1.24 0.94 1.22 0.79 1.11 0.11 1.73 0.96 1.13 0.71 0.62 0.84 1.52 1.58 0.54 1.22 1.01 1.06 0.50 0.84 1.53 0.62 1.25 0.67 0.76 0.57 0.73 1.75 1.00 1.30 1.14 0.33 0.69 1.38 1.24 0.80 1.18 1.03 1.00 1.81 1.10 0.14 1.80 1.08 1.22 1.33 0.92 1.51 1.07 0.80 0.12 1.08 1.03 1.73 0.84 1.79 1.91 1.77 1.82 1.50 1.25 0.40 1.51 0.77 0.81 0.88 1.18 1.23 1.10 1.23 0.49 0.87 0.95 1.11 1.49 0.81 1.45 0.89 1.12 0.53 1.22 0.85 0.39 1.61 1.05 1.42 0.86 0.95 1.92 0.58 1.67 1.15 0.60 0.09 0.70 0.64 1.03 1.33 0.59 0.90 0.77 0.18 0.60 0.44 0.18 1.94 1.43 0.97 1.12 0.74 0.68 0.74 0.88 1.12 1.00 1.10 1.33 1.41 1.39 0.45 0.89 0.43 1.47 1.33 0.46 1.40 0.45 0.84 1.20 0.79 0.98 0.96 0.15 1.23 1.23 0.10 0.07 1.44 0.93 1.12 0.84 0.53 0.65 1.62 0.32 1.04 1.28 0.60 1.37 0.97 0.51 0.73 0.60 0.11 0.93 0.93 0.76 1.08 0.82 1.25 1.10 1.43 1.29 0.81 0.86 0.27 0.85 0.94 1.16 1.00 1.30 0.88 1.38 0.47 1.65 1.33 0.99 1.13 0.79 0.93 0.71 1.01 1.19 1.02 1.02 0.45 0.93 1.38 1.29 0.51 0.56 1.69 1.61 1.83 0.75 1.05 0.96 1.02 1.03 0.52 1.05 1.37 0.31 1.31 1.61 0.53 1.67 0.72 1.03 0.69 1.32 1.25 1.81 0.44 1.32 0.88 1.93 0.36 1.02 0.83 1.49 0.81 1.58 1.44 1.08 1.40 1.87 1.69 0.92 1.51 1.10 1.61 0.65 1.26 0.65 1.31 0.44 0.28 1.65 1.62 1.85 1.13 1.66 1.39 0.95 0.82 0.30 1.07 0.40 0.63 1.41 0.18 1.07 0.87 0.18 0.46 1.50 0.74 1.41 0.73 1.02 0.40 0.98 1.27 1.79 1.42 0.84 1.06 1.06 0.64 1.42 1.27 0.70 1.09 1.13 0.46 1.38 0.46 0.32 0.73 0.61 1.31 0.76 0.37 1.30 1.06 1.12 0.65 1.33 1.92 0.56 0.59 1.23 1.30 0.77 1.65 1.20 0.84 1.35 0.77 1.22 1.37 1.15 1.16 0.74 0.92 1.44 1.25 0.55 1.22 0.58 0.70 0.85 0.72 1.75 0.85 1.32 1.31 1.23 0.96 0.53 1.29 0.39 0.66 1.08 1.27 0.75 1.43 0.51 0.81 0.66 1.24 1.88 1.45 1.02 1.09 0.28 0.54 0.92 1.61 0.08 1.66 0.86 0.45 0.26 0.64 0.91 0.89 0.43 0.89 1.75 0.99 0.36 0.69 1.73 1.27 1.20 1.65 1.03 0.42 1.34 1.19 0.94 1.03 0.41 0.81 0.90 0.19 0.34 1.52 0.20 0.88 0.72 0.45 0.62 1.03 0.94 1.20 1.30 1.25 1.16 0.88 0.87 0.32 0.96 1.27 1.63 0.56 0.68 1.10 0.88 1.26 1.35 0.70 0.71 1.36 1.02 0.92 1.31 1.10 1.07 1.42 0.53 1.05 0.97 1.50 1.28 1.66 1.22 1.27 1.32 1.79 0.87 1.23 0.95 1.44 0.70 0.73 1.83 1.43 0.93 0.64 1.69 0.83 0.66 1.85 1.74 1.33 0.35 0.78 1.89 0.30 1.09 0.82 0.81 0.72 0.18 0.95 0.66 0.79 0.88 1.31 1.28 0.21 1.20 0.90 1.22 0.66 0.24 1.22 0.74 0.80 1.30 0.81 0.52 1.31 1.25 1.00 1.26 1.13 1.20 0.52 1.26 0.73 0.68 0.55 0.89 1.35 1.08 1.17 1.76 0.99 1.09 1.53 1.19 1.79 0.71 0.81 0.52 0.46 1.48 0.62 0.35 1.57 1.13 1.02 1.21 0.91 0.99 1.64 1.10 1.57 1.75 0.76 0.92 0.46 1.23 0.77 1.06 1.01 1.07 1.10 1.03 0.57 0.44 1.20 0.65 0.34 1.15 0.67 1.33 1.48 1.23 1.13 1.58 0.49 1.16 0.93 0.59 0.21 1.73 0.57 1.17 0.77 1.02 0.40 0.58 0.91 1.12 1.09 1.17 0.35 0.16 0.52 0.79 0.77 1.13 0.88 1.25 0.63 1.10 1.61 0.90 0.50 1.55 0.71 0.16 1.05 0.34 1.07 1.29 0.64 1.18 0.72 1.19 0.69 1.37 0.98 1.82 1.28 1.07 1.09 1.05 1.57 0.71 0.52 1.49 1.43 1.68 1.10 0.50 1.17 1.10 1.14 1.63 1.29 0.41 0.95 1.54 0.86 0.17 0.25 1.54 1.33 0.82 1.10 1.22 1.19 1.41 1.25 0.75 0.75 0.94 0.63 0.22 0.72 0.86 1.04 0.64 0.62 0.80 0.79 0.98 0.34 1.30 1.43 1.14 1.22 0.88 0.53 1.34 1.47 1.22 1.61 1.88 0.33 0.96 1.69 0.10 1.32 0.63 0.47 0.92 0.83 0.54 0.89 1.61 1.09 0.87 0.69 0.93 1.42 1.15 1.82 1.14 0.66 0.87 1.53 1.80 0.59 0.71 1.23 0.84 1.16 1.01 1.45 0.89 0.83 0.98 1.29 0.77 0.89 1.07 0.44 1.77 0.21 0.51 0.82 1.74 1.06 0.84 0.69 1.39 0.77 1.17 0.49 1.01 1.59 0.80 0.93 1.06 1.07 1.58 0.93 0.87 1.09 0.49 1.44 0.31 1.25 0.27 1.41 1.12 1.36 1.04 0.51 1.44 1.68 0.47 1.35 0.59 1.05 1.21 0.96 0.70 0.98 0.95 0.25 1.41 1.00 0.90 0.55 1.08 0.35 0.84 0.87 1.13 0.51 0.40 0.85 0.69 1.07 1.24 0.72 0.93 1.09 1.21 1.16 0.87 0.84 1.20 1.14 1.63 1.67 0.13 1.13 0.36 1.46 0.53 1.24 1.88 1.28 0.96 1.39 0.94 0.55 0.95 1.47 1.34 1.61 0.66 1.29 0.93 0.62 0.91 1.92 1.19 0.88 0.63 1.00 0.51 0.71 0.24 1.04 1.32 1.06 1.39 1.02 1.09 0.80 1.51 0.78 1.92 0.84 0.95 1.13 1.39 0.92 1.02 1.21 1.62 1.34 0.61 1.33 1.01 0.69 0.85 1.19 1.14 1.32 0.88 1.55 1.28 0.88 0.42 1.65 0.36 1.04 1.35 1.67 0.50 0.87 0.83 1.11 1.10 1.06 0.88 1.24 1.06 1.46 1.23 1.52 1.10 0.55 0.93 0.81 1.58 0.78 0.75 1.39 1.33 0.84 1.06 1.36 1.20 0.62 0.93 1.00 0.71 0.48 0.79 1.09 0.98 1.80 1.77 0.59 1.65 1.30 0.51 0.83 0.48 0.13 0.58 1.43 1.70 0.94 1.21 0.86 0.89 0.92 0.86 1.76 0.95 1.20 1.72 1.15 0.46 0.61 1.40 0.33 0.95 0.60 1.29 1.34 1.13 1.84 0.78 1.48 0.66 0.17 0.70 1.59 0.60 0.21 1.23 1.10 0.81 0.33 1.16 1.27 0.95 1.27 0.71 0.47 0.45 0.75 0.96 0.32 0.52 0.55 1.06 0.93 0.36 0.96 0.93 0.81 1.35 0.62 0.85 0.43 0.72 1.44 1.51 0.23 1.28 0.79 1.43 1.21 0.98 0.30 1.42 0.79 1.19 0.82 1.48 1.34 0.42 0.88 1.54 0.96 0.89 0.16 0.48 0.11 0.55 0.38 1.52 0.74 0.57 0.77 1.81 0.27 0.89 1.15 1.26 1.25 0.88 1.47 0.78 0.83 1.00 0.31 1.37 0.24 1.61 1.02 1.11 1.64 0.43 1.43 0.92 0.85 1.08 1.15 0.90 1.21 1.17 1.43 1.57 1.49 0.68 0.59 0.79 0.79 1.02 0.92 0.90 0.73 1.10 0.86 0.85 1.91 0.59 1.55 1.01 1.35 1.54 0.50 0.16 0.56 1.51 1.12 0.26 1.41 0.74 0.35 0.34 0.58 0.60 1.11 1.18 1.31 0.38 1.06 1.09 1.73 1.12 1.03 1.71 0.71 0.71 1.02 1.32 0.99 1.75 0.53 0.54 1.65 0.64 0.46 1.34 0.35 1.05 0.82 0.81 1.20 1.60 0.58 0.84 0.84 0.66 1.52 1.20 1.14 0.89 1.58 0.79 1.69 1.30 0.59 1.04 0.63 1.01 0.56 1.77 1.43 0.77 0.65 1.10 0.82 1.38 1.22 1.32 1.01 1.41 0.74 1.39 1.09 0.57 1.24 1.06 1.77 0.61 1.80 1.21 0.71 1.01 1.76 0.83 0.96 1.36 0.69 1.06 1.16 0.44 0.98 1.07 1.32 1.18 1.40 1.72 0.99 1.04 1.07 0.51 1.11 0.72 1.63 1.59 0.41 1.20 1.52 1.15 0.95 0.94 0.72 0.45 0.40 1.45 1.36 0.49 0.85 1.28 1.00 1.27 0.90 0.80 1.73 0.25 1.29 1.03 0.87 1.72 0.97 1.72 1.15 0.80 1.43 0.47 0.95 1.84 0.21 1.27 0.60 0.64 0.71 0.90 1.15 0.83 0.80 0.45 1.77 0.95 1.33 1.62 1.15 1.13 1.10 0.31 0.90 1.59 1.60 1.19 1.13 0.87 0.58 0.88 0.59 1.55 1.24 1.20 0.63 0.74 1.71 0.43 0.99 1.23 1.52 1.34 1.44 1.57 0.55 1.37 1.27 1.05 1.09 0.90 1.58 1.46 1.69 1.92 0.92 1.28 0.57 1.08 0.84 1.02 1.10 1.52 1.30 0.89 0.84 0.11 0.42 0.73 1.46 0.81 0.79 0.82 0.71 1.35 1.54 0.95 0.76 1.01 1.06 0.46 0.68 1.33 1.14 0.23 0.69 0.98 1.12 1.82 1.70 1.40 0.56 0.88 0.82 1.38 0.80 0.77 1.40 0.60 1.14 1.13 1.87 0.31 0.91 0.83 1.31 0.83 1.57 1.20 0.61 0.26 0.44 0.90 1.13 0.36 0.33 1.10 0.60 0.18 0.54 1.10 1.24 0.74 0.65 1.19 1.54 1.66 1.48 0.81 1.07 1.88 0.67 1.58 1.40 1.77 0.79 0.79 0.80 0.84 1.47 0.70 1.49 0.97 0.94 0.59 0.95 0.39 0.47 1.88 1.75 1.79 1.50 1.58 1.12 0.75 1.46 0.61 1.81 0.93 1.36 0.75 1.00 0.92 1.12 1.33 0.43 1.41 0.72 1.23 0.41 1.43 0.41 0.80 0.62 0.98 1.25 1.28 0.87 0.72 1.00 0.86 1.18 0.37 1.25 1.74 1.57 0.50 1.20 0.22 1.04 1.79 0.92 0.54 1.29 0.77 0.32 0.72 0.90 1.40 0.68 0.79 0.30 0.24 0.62 0.33 0.65 0.96 1.22 1.35 0.77 0.80 1.77 0.59 0.61 1.81 1.12 1.53 0.91 0.96 1.22 1.19 0.42 1.44 1.64 0.15 0.93 0.51 1.47 0.35 1.09 1.35 1.77 1.64 1.65 1.21 0.89 0.73 1.53 0.95 0.96 1.59 1.04 0.58 1.19 1.57 1.10 0.47 0.80 1.56 1.72 1.33 0.16 0.91 1.24 0.87 0.95 1.10 0.55 0.50 0.61 1.01 1.00 0.60 0.60 1.27 0.92 0.92 1.67 0.77 0.68 1.12 1.11 1.64 0.89 0.40 0.23 1.23 0.90 1.05 0.97 0.83 0.91 0.96 1.58 1.51 1.37 0.91 0.84 0.14 0.70 1.24 0.96 1.17 1.30 0.38 0.52 1.16 0.96 1.03 0.85 0.80 1.16 0.69 1.26 0.73 1.37 0.89 1.44 1.19 1.26 1.01 1.79 1.22 1.28 1.28 0.78 1.35 0.80 0.94 0.87 1.01 1.63 0.57 0.95 0.82 1.34 0.97 0.99 0.87 0.45 1.42 1.24 0.17 1.81 1.09 1.76 0.92 0.99 0.47 1.26 1.13 1.12 0.75 1.30 1.39 0.78 0.98 0.57 1.05 0.25 0.06 1.24 1.40 1.47 1.17 1.16 1.35 1.40 0.40 0.71 1.45 1.59 1.51 0.58 0.55 0.70 0.83 0.59 0.17 0.12 0.79 1.63 0.56 1.23 0.75 0.74 0.42 1.63 0.50 1.49 \n",
            "1.03 1.65 1.12 0.10 0.29 0.63 1.50 1.22 0.31 1.03 1.39 1.25 1.11 0.74 1.07 0.66 1.40 0.96 0.54 0.81 1.28 0.92 0.70 0.87 0.58 1.05 0.67 0.77 0.17 0.40 0.72 1.33 0.36 0.64 1.35 0.74 0.87 0.41 0.78 1.58 1.17 0.34 0.94 1.63 0.61 1.34 1.06 0.46 0.97 1.33 0.53 1.95 0.71 0.99 0.65 0.85 1.21 0.67 1.28 1.24 1.31 1.23 0.27 0.79 1.77 0.56 1.17 0.72 0.87 0.36 1.29 1.35 1.39 0.63 0.29 1.58 1.46 0.97 1.49 0.96 0.88 0.58 1.03 0.91 1.01 0.43 1.48 0.80 0.78 0.56 1.31 0.66 0.94 0.50 0.39 0.70 0.99 1.30 1.58 0.92 0.49 0.90 1.12 0.84 1.13 0.97 0.52 1.22 1.26 0.89 1.19 0.92 0.87 1.21 0.43 1.05 1.47 0.89 1.65 1.49 1.12 1.23 0.09 1.11 1.18 1.00 1.59 0.56 0.14 0.91 0.89 0.49 0.90 0.97 1.09 1.32 0.91 0.86 1.01 0.35 0.96 0.57 1.27 1.02 0.89 0.97 0.87 1.15 1.84 0.30 1.57 1.14 0.18 1.48 0.97 1.39 0.17 1.47 1.08 0.85 0.41 1.76 1.28 1.04 1.03 1.04 0.96 1.08 0.18 1.33 0.38 1.07 0.67 0.99 1.03 0.73 0.66 0.71 0.40 1.04 1.08 1.03 0.27 1.17 0.67 0.60 1.21 1.60 1.21 0.64 0.43 0.67 0.85 1.00 1.12 0.69 1.12 1.23 0.84 0.84 0.90 0.55 1.09 0.99 0.73 0.54 1.00 1.23 0.59 1.10 1.27 0.92 1.52 0.79 0.54 0.85 1.05 0.55 1.55 1.46 1.16 0.43 1.19 1.02 0.90 0.50 0.92 1.58 0.57 0.78 1.00 0.54 1.04 1.21 0.62 0.86 0.65 0.96 0.96 1.63 1.10 1.02 1.55 0.45 0.97 1.23 0.88 1.03 0.85 1.50 0.90 1.26 0.65 0.38 1.20 0.46 0.15 1.31 1.09 0.81 1.00 1.04 0.80 1.79 1.31 1.13 1.64 0.76 0.62 0.90 1.17 1.10 0.85 1.01 1.18 1.02 0.85 1.07 1.13 1.30 1.15 0.65 0.81 1.09 0.56 1.23 0.36 1.03 0.75 1.16 0.85 1.13 0.23 0.33 1.07 0.79 1.05 1.02 0.85 1.29 1.09 1.13 0.86 1.67 1.20 0.56 1.02 0.73 0.89 0.60 0.70 1.19 1.83 0.61 1.31 1.08 0.43 0.86 1.38 0.91 0.37 0.63 0.15 0.63 1.43 1.02 1.61 0.88 1.40 1.11 1.40 1.12 0.41 1.12 0.51 1.38 0.50 1.26 0.37 1.71 1.11 0.93 0.93 0.16 0.31 1.04 1.48 1.54 1.14 0.70 0.71 1.53 1.09 0.88 1.68 1.26 0.31 0.52 1.00 0.57 0.96 1.02 0.78 0.34 1.24 0.58 1.11 1.17 0.89 0.66 1.63 0.36 1.10 1.17 0.54 1.41 1.36 0.94 1.00 1.06 1.31 1.19 0.74 1.62 1.42 1.21 1.19 0.97 0.42 1.39 0.89 0.47 0.24 0.39 0.68 1.49 1.10 1.41 1.05 0.49 1.31 1.51 1.26 1.78 1.63 0.65 1.00 0.77 1.53 1.49 0.63 1.20 0.66 0.58 0.65 1.17 0.78 0.45 1.16 1.71 0.42 1.32 0.47 1.67 0.26 1.22 1.14 1.63 1.05 0.50 1.29 1.65 0.35 1.10 1.34 1.31 1.16 1.20 0.72 0.63 1.04 0.88 1.27 0.97 0.72 1.01 1.14 1.08 0.75 1.01 0.99 1.87 0.94 0.76 0.94 1.65 0.23 1.15 1.04 0.82 1.59 1.78 1.48 1.23 1.05 1.33 0.56 1.17 0.26 1.17 1.33 1.18 1.35 1.06 0.46 1.16 0.71 0.77 1.80 0.42 1.25 0.88 0.96 0.30 0.98 1.43 1.29 0.86 0.95 1.03 1.81 0.44 1.12 0.69 1.23 0.76 0.87 0.27 0.69 1.05 1.04 0.97 1.10 0.97 0.75 1.46 0.19 1.07 1.14 1.22 0.89 1.83 1.63 0.59 1.67 0.99 1.12 1.04 0.77 1.27 1.03 1.09 0.64 1.53 0.93 1.13 0.74 0.58 1.07 0.70 0.81 0.45 1.63 1.15 1.51 0.95 1.15 0.75 1.19 0.57 1.02 0.95 0.67 1.14 1.70 0.46 0.53 1.43 0.40 0.58 0.99 0.44 1.55 0.94 0.47 0.88 0.21 1.26 0.36 0.61 1.26 1.57 0.98 0.95 0.58 0.30 1.05 0.72 0.93 1.36 1.17 1.90 1.07 1.26 1.58 1.50 0.94 0.61 1.09 0.31 1.09 0.24 0.35 0.75 0.63 0.70 1.35 0.18 0.75 1.85 1.31 1.15 1.43 1.17 0.32 1.18 1.09 1.55 1.38 1.73 0.40 0.82 1.01 1.16 1.45 1.10 1.37 1.02 1.02 1.31 0.68 0.74 0.91 1.20 1.59 1.30 1.35 1.74 1.12 1.13 0.93 1.34 1.48 1.09 0.55 0.82 0.91 0.97 1.85 1.12 1.10 1.43 1.55 0.81 1.07 1.25 1.17 1.30 0.94 1.14 0.81 1.70 1.52 1.54 0.85 0.80 1.09 1.41 0.39 1.31 0.16 0.46 1.15 0.99 0.14 0.58 1.09 0.66 0.96 0.97 0.86 0.77 0.98 1.58 1.39 0.83 1.46 0.89 1.05 0.71 1.02 0.14 1.57 0.71 1.00 1.34 0.43 1.82 1.28 0.79 1.30 1.23 0.91 1.37 1.02 1.16 0.36 0.14 1.09 1.46 0.52 0.95 0.92 0.38 1.17 0.88 0.79 0.22 1.24 1.67 0.66 1.29 1.10 0.94 1.27 0.30 1.21 0.76 0.02 0.32 0.31 1.66 1.30 1.79 1.47 0.79 1.27 1.13 0.51 0.58 1.47 0.60 1.13 0.80 1.50 1.35 1.33 0.90 0.89 0.16 1.15 0.47 1.05 0.81 0.66 0.33 1.27 0.80 0.28 0.55 1.74 1.59 0.90 1.70 0.17 1.13 1.83 0.74 1.19 0.41 0.95 0.98 0.68 1.62 0.38 1.74 1.06 1.19 0.80 0.75 0.74 1.29 0.49 1.43 1.60 0.53 0.60 1.76 1.29 1.24 0.54 0.80 0.31 1.55 0.87 1.08 1.18 1.17 0.41 1.34 0.45 0.55 1.37 1.34 0.69 0.34 1.57 0.82 1.12 1.00 1.68 0.59 1.45 1.52 0.38 0.88 0.72 0.89 0.73 0.76 0.81 1.64 1.23 1.26 0.84 1.33 1.33 0.38 0.69 1.66 0.76 0.89 0.95 0.58 1.00 1.10 1.43 1.19 1.20 0.99 0.71 0.55 1.23 0.83 0.83 0.98 1.01 1.07 0.65 0.65 0.97 0.47 0.49 1.05 0.12 1.73 0.34 0.87 1.22 0.49 1.19 0.64 1.34 1.17 1.36 0.65 1.58 0.74 1.78 1.76 1.82 0.73 0.76 1.74 0.30 1.04 0.70 0.68 1.40 1.02 0.68 0.09 0.78 0.33 0.61 1.47 1.58 0.60 0.80 1.32 1.57 0.57 1.05 1.29 1.10 1.20 0.99 1.05 1.13 1.33 1.46 1.18 0.99 1.38 1.12 1.89 1.06 0.94 0.70 1.55 0.55 0.59 1.05 1.30 1.01 0.92 1.42 1.52 0.88 1.21 0.60 1.68 1.55 1.78 0.86 1.06 0.10 0.94 1.27 1.32 0.86 0.76 1.35 0.70 0.18 1.22 1.00 0.44 0.53 0.79 1.56 1.80 1.49 0.80 0.97 1.05 1.36 1.11 0.09 0.92 0.71 1.05 1.05 1.26 1.70 0.98 0.89 0.90 1.50 0.14 0.82 1.29 1.01 0.89 1.19 1.37 0.97 1.61 0.90 0.61 0.90 1.85 1.35 1.19 1.46 1.31 1.53 1.47 0.98 0.66 1.16 1.07 1.45 0.16 0.54 0.94 1.35 1.26 1.56 1.55 0.77 0.31 0.46 0.85 1.13 0.60 0.54 0.42 1.35 0.32 1.34 1.35 1.05 1.39 1.05 1.62 1.80 1.13 0.71 0.69 1.49 1.12 0.97 1.00 1.12 1.21 1.57 1.15 0.19 1.23 0.48 1.08 0.78 0.55 1.20 1.33 1.53 0.71 1.00 0.82 1.01 0.57 0.61 1.20 0.26 1.05 0.28 1.04 1.34 0.57 0.84 1.23 1.36 1.87 0.63 1.47 0.70 0.23 0.77 1.12 0.87 1.78 1.31 1.22 0.41 1.20 1.69 0.62 1.36 0.41 1.16 0.65 0.94 1.17 0.31 0.73 0.47 1.33 1.34 0.44 1.35 1.01 1.07 1.09 1.11 0.44 1.39 1.13 0.96 1.03 0.59 1.46 0.30 0.85 1.34 1.38 0.91 0.73 1.03 0.41 1.32 1.40 0.92 1.05 0.82 1.16 0.85 1.48 0.42 0.77 0.61 1.45 1.56 0.50 1.00 0.71 1.74 1.06 1.63 0.54 1.18 0.88 1.34 1.17 0.69 1.52 1.10 0.82 1.16 1.23 1.21 0.50 1.06 0.61 0.65 1.13 0.87 0.85 1.37 0.97 0.95 0.36 1.46 0.71 0.49 1.78 0.89 0.65 0.84 1.63 1.42 0.31 0.77 1.51 0.17 1.19 0.97 1.17 0.73 1.04 0.82 0.91 1.12 1.66 0.82 1.44 1.04 0.53 0.90 0.94 1.52 1.20 0.67 0.92 1.25 0.60 1.79 0.77 1.08 0.85 0.72 1.13 1.04 1.57 0.70 1.02 0.64 1.71 0.58 0.70 1.60 0.89 1.82 1.29 1.09 0.78 0.44 1.56 1.58 0.41 0.64 1.52 1.64 0.60 1.86 1.05 1.62 0.84 1.59 0.34 1.27 0.48 1.04 1.18 0.18 0.92 1.04 1.12 0.66 0.91 1.03 0.98 0.90 1.10 0.96 1.18 1.56 0.95 0.70 1.23 0.74 1.71 1.58 0.47 1.55 0.77 1.35 1.23 1.58 0.74 0.76 0.76 0.57 0.93 0.84 0.15 1.31 0.37 0.68 1.13 1.22 0.81 0.65 0.82 0.36 0.75 1.48 1.44 1.22 1.32 0.53 0.64 0.33 1.73 0.85 0.25 0.74 0.66 0.10 0.60 1.05 1.58 0.85 1.58 0.39 1.12 1.37 1.75 1.78 0.71 1.32 0.72 1.03 1.44 0.87 1.59 0.38 1.46 1.19 1.29 0.93 0.48 0.18 0.99 0.70 0.59 0.68 1.07 1.70 0.85 0.54 0.51 0.62 1.15 1.00 0.39 0.85 1.23 1.11 0.99 0.93 1.81 0.91 1.33 0.38 1.20 0.62 0.83 0.68 1.05 0.42 0.62 1.31 0.30 1.06 1.21 0.88 0.62 0.88 1.41 1.12 0.17 1.32 0.98 0.99 0.68 0.46 1.69 1.14 1.17 1.30 1.20 1.39 0.98 0.76 0.53 1.00 0.62 0.70 1.32 0.62 1.10 1.30 0.85 0.79 1.63 1.41 1.27 0.65 0.07 0.64 0.29 1.30 0.97 0.52 0.69 1.28 0.23 0.59 1.00 1.11 1.48 1.47 0.33 1.02 0.54 0.99 0.31 0.75 1.28 1.57 0.41 0.76 1.44 0.72 0.74 1.08 0.36 0.98 0.68 1.07 1.66 1.04 0.36 1.26 1.06 1.60 0.68 1.11 0.73 0.57 0.66 0.69 1.21 1.70 0.66 1.10 0.85 1.29 0.95 0.84 1.36 1.47 0.82 1.16 0.40 1.02 1.37 1.08 1.36 1.47 0.56 1.35 0.72 0.61 1.18 1.67 0.90 1.58 0.71 0.28 1.45 1.18 0.99 1.40 1.03 1.38 1.43 1.00 0.36 0.81 0.06 1.06 0.61 0.69 1.37 1.44 1.26 0.64 1.88 0.62 0.91 0.51 0.72 0.48 1.12 1.61 0.76 1.15 1.31 0.71 0.81 0.51 0.77 1.33 1.19 0.56 1.94 0.44 0.58 0.73 1.21 0.88 1.01 1.36 0.88 1.02 1.21 0.77 0.68 1.63 1.04 0.98 0.26 0.62 1.33 0.55 0.69 0.51 0.46 1.04 0.93 1.03 0.59 1.12 0.88 1.14 0.95 0.88 1.54 1.06 0.84 0.41 1.03 1.25 0.80 0.83 0.35 0.86 0.64 1.20 0.74 1.43 0.48 1.90 0.81 0.89 1.56 1.19 0.22 1.09 0.71 0.74 1.78 0.99 0.59 0.95 0.54 1.02 1.69 1.04 0.88 1.15 1.24 0.04 0.76 1.49 1.07 1.53 0.83 1.28 0.71 0.75 0.60 1.28 0.70 1.78 1.26 1.02 1.26 0.96 1.21 1.48 1.67 0.13 0.52 0.92 1.63 1.50 1.44 1.51 1.10 0.71 1.22 0.87 0.79 0.49 1.27 1.28 0.98 1.44 0.83 0.74 0.03 0.69 0.02 0.59 1.51 1.49 1.01 0.21 1.19 0.80 1.68 0.42 1.51 1.17 0.22 0.79 1.15 0.70 1.68 1.29 0.57 0.90 1.15 0.39 0.83 0.82 1.28 1.18 1.09 1.13 1.27 0.54 1.40 1.58 0.53 1.25 0.65 1.69 0.28 1.15 1.28 0.61 1.20 0.37 1.14 0.59 0.42 1.81 1.37 0.89 1.26 0.99 1.31 0.73 1.78 0.68 0.85 1.62 1.09 0.33 0.48 0.63 1.07 0.72 1.84 1.33 0.76 1.03 0.02 1.66 1.64 0.85 0.64 0.54 0.45 0.95 0.81 0.83 1.04 1.30 1.17 0.98 1.96 1.00 0.77 1.78 1.00 0.90 1.09 0.37 1.30 0.47 0.91 0.97 0.86 1.81 0.91 0.95 1.81 1.86 1.60 0.97 1.25 1.23 0.29 0.87 0.90 0.70 1.64 0.76 0.96 0.51 1.36 0.74 1.41 0.73 1.23 1.61 1.58 1.82 0.42 0.47 1.04 1.14 1.84 1.18 1.46 1.68 1.16 0.99 1.01 0.58 0.45 1.71 1.02 0.90 0.22 0.75 1.55 0.93 0.78 0.21 0.82 1.08 0.29 1.54 0.82 1.52 1.32 1.30 0.74 0.76 0.58 0.22 0.40 1.53 1.26 1.44 0.60 1.06 0.60 1.18 0.74 0.69 0.92 1.38 1.21 0.62 0.65 0.92 0.99 0.24 0.17 1.34 0.19 0.66 1.00 1.23 1.53 0.78 0.92 0.11 0.30 0.92 0.57 0.99 1.29 0.81 1.91 0.23 0.54 0.91 0.71 1.28 1.05 0.68 1.22 1.10 1.53 0.46 0.86 0.66 1.68 1.60 1.62 1.68 0.72 0.69 1.71 0.68 1.03 0.74 1.15 1.78 0.87 0.78 0.69 0.88 0.92 0.96 1.32 1.69 0.23 0.47 1.36 0.71 0.50 0.63 0.30 1.33 0.65 0.90 0.56 0.72 0.28 1.02 0.32 0.63 1.11 0.49 1.25 0.85 0.64 0.40 0.90 1.12 0.84 1.90 0.80 0.88 1.31 0.67 0.62 1.18 0.40 1.19 0.86 0.40 0.52 1.45 1.54 0.96 1.58 0.78 1.49 0.46 0.57 1.42 1.43 0.91 1.25 1.49 1.12 0.61 0.70 1.06 0.62 0.62 0.88 0.58 1.07 1.17 1.16 0.82 1.18 0.42 0.82 0.54 0.80 1.58 1.22 0.73 0.66 1.04 0.75 0.91 0.66 1.46 0.65 1.40 1.01 1.26 0.72 0.77 0.95 1.00 0.99 0.99 1.08 1.18 1.65 0.66 0.18 1.12 1.40 1.66 1.34 0.23 1.72 0.56 0.36 0.83 0.30 0.98 1.85 1.21 1.27 0.80 0.98 1.28 1.44 0.77 0.86 0.82 1.02 1.23 0.94 1.72 0.87 0.61 0.86 1.22 0.68 0.58 0.93 1.03 1.79 1.14 0.82 1.20 0.35 1.22 0.48 1.54 0.64 1.07 0.98 1.64 1.31 1.33 1.07 0.62 1.16 1.50 0.72 0.83 1.14 1.37 0.99 0.99 1.07 1.12 0.35 0.70 0.98 0.89 1.39 0.91 1.27 1.54 1.11 1.07 1.42 0.88 0.34 1.04 0.93 0.44 0.92 0.92 1.19 0.94 1.33 0.13 1.25 1.60 1.05 0.62 1.10 0.89 0.36 0.84 1.09 0.55 1.44 0.91 1.30 0.20 0.70 0.23 1.02 1.32 0.48 1.54 1.45 1.00 1.37 1.10 1.12 0.47 1.14 1.19 1.23 1.06 0.75 0.90 1.11 0.83 0.17 1.16 0.82 0.42 1.00 0.65 1.18 1.69 0.50 0.75 1.29 0.67 1.11 0.79 0.79 0.80 1.00 0.58 1.12 1.02 1.52 1.26 0.79 1.02 0.83 1.03 1.59 1.14 1.26 0.90 0.56 1.02 1.67 1.39 0.60 0.91 1.09 0.83 1.11 0.18 1.61 1.04 0.90 1.87 1.11 1.22 0.47 0.22 1.84 0.91 1.04 0.55 1.00 0.01 0.21 1.04 1.40 1.00 1.26 0.45 0.65 1.04 0.91 1.25 0.89 1.17 1.00 1.06 0.10 1.09 0.25 0.13 1.22 0.94 1.00 0.86 1.07 0.76 1.19 0.72 1.18 1.01 0.62 1.17 1.13 1.02 1.40 1.02 0.28 1.09 0.37 0.94 0.87 1.41 0.72 0.14 1.03 1.07 1.22 1.37 0.51 0.73 1.55 1.53 0.73 1.13 1.58 0.53 0.78 1.50 1.08 0.39 0.81 0.77 1.72 0.38 1.53 1.13 0.88 0.93 1.28 1.70 1.12 0.31 1.17 0.40 0.47 1.37 1.28 0.31 1.27 1.22 1.81 0.91 1.01 0.30 0.89 1.16 0.23 0.92 1.28 1.66 1.12 1.03 0.16 0.38 1.03 1.27 0.96 1.53 1.01 0.27 0.84 0.92 0.90 0.47 0.16 0.94 1.15 0.67 1.30 0.75 0.65 1.17 1.19 0.58 0.54 1.10 1.28 0.45 0.86 0.36 1.04 0.30 1.26 1.51 1.03 1.88 1.29 1.30 0.76 1.68 0.72 0.68 1.81 1.19 1.05 0.70 0.83 1.28 0.98 0.64 1.06 0.70 1.57 0.82 0.87 0.62 1.29 0.60 1.44 0.77 1.34 0.58 1.48 0.26 0.65 1.47 1.42 1.06 1.16 0.31 1.39 0.62 1.24 0.80 1.00 1.17 1.05 1.51 1.62 1.00 0.69 0.99 0.65 1.09 0.92 0.84 0.32 1.00 1.67 0.24 1.37 1.03 1.17 0.96 0.32 1.06 1.43 1.11 1.08 0.90 0.60 1.33 1.19 0.48 1.13 0.55 1.14 0.92 1.11 1.10 0.83 1.45 1.20 1.34 0.76 0.30 0.98 1.29 0.95 1.05 1.51 1.57 1.18 0.96 1.35 0.72 1.21 1.43 0.72 0.70 1.01 0.85 0.62 1.18 0.94 1.64 0.81 1.10 1.69 0.28 1.13 1.20 1.16 0.74 1.41 1.37 1.45 0.42 0.38 0.63 1.81 0.77 0.48 1.62 0.94 0.19 1.90 1.40 1.04 0.94 1.59 0.87 1.54 1.11 0.89 0.24 1.01 1.32 0.89 1.66 1.84 1.89 1.26 1.78 0.43 0.75 1.03 1.06 0.91 0.50 0.92 0.49 1.77 1.42 0.76 0.48 0.94 1.34 1.66 0.50 1.84 1.11 0.87 0.45 1.35 0.59 1.70 1.20 0.91 1.12 1.71 1.27 0.99 0.85 0.72 0.73 0.60 0.43 1.03 0.27 0.83 0.64 0.94 1.01 1.46 1.52 0.74 0.81 0.40 1.37 1.02 0.68 0.95 1.09 1.00 1.36 0.21 1.37 0.83 1.00 1.51 1.46 1.33 0.98 0.94 0.85 1.46 1.57 0.66 1.40 1.01 1.49 0.76 0.39 1.25 0.88 0.92 1.02 0.62 0.97 0.36 1.52 1.36 1.25 0.74 0.66 1.40 0.99 1.00 1.74 0.77 1.01 0.97 0.95 1.04 1.16 0.73 1.23 0.77 1.09 1.14 0.28 0.89 1.69 0.65 1.14 1.06 1.13 0.20 1.62 0.99 0.64 1.48 1.80 0.36 1.76 0.64 1.04 1.33 1.43 1.17 1.40 0.74 1.26 0.61 1.17 1.68 1.30 1.69 0.41 1.00 0.56 0.21 1.17 1.32 0.51 0.18 1.73 0.45 0.85 0.88 1.64 1.85 1.72 1.06 1.60 1.28 0.71 0.74 1.04 0.48 0.57 0.46 0.58 1.30 0.97 1.45 0.74 0.57 0.84 0.58 0.69 0.58 0.35 0.27 0.40 0.93 1.41 1.27 0.30 1.40 0.74 0.89 0.16 0.93 1.09 1.43 0.37 1.18 1.33 1.11 0.20 1.70 1.43 0.60 1.54 1.01 0.86 0.75 1.35 1.00 1.18 1.24 1.43 1.27 0.87 1.50 1.43 0.70 1.18 0.59 1.29 1.99 0.50 1.16 0.41 1.30 0.60 0.14 1.96 0.80 0.80 1.91 0.51 1.09 1.90 1.40 1.27 1.35 0.11 0.62 0.67 1.10 1.47 1.30 1.66 0.25 0.40 0.69 0.77 0.60 0.45 1.86 1.36 1.49 0.72 0.99 1.04 0.67 0.34 1.93 0.06 0.45 0.34 1.37 0.91 0.78 0.94 1.08 0.85 1.78 1.70 0.96 0.85 1.24 0.59 1.17 1.35 1.12 0.76 1.81 1.44 1.04 1.22 0.70 0.70 0.63 0.25 1.15 1.22 1.27 0.56 1.48 1.06 1.61 1.09 1.49 1.02 0.92 0.65 1.30 1.09 0.76 1.52 0.42 1.28 1.57 1.13 0.77 0.63 1.01 1.80 1.24 1.03 1.06 0.77 1.03 1.30 1.20 0.69 0.58 1.31 0.82 1.18 1.63 0.96 1.54 1.14 0.59 0.93 0.85 1.02 0.57 0.68 1.15 1.38 1.35 0.88 1.12 0.75 0.89 0.39 0.47 1.20 0.70 0.70 0.84 0.43 1.04 1.16 1.48 0.93 1.22 0.98 0.87 1.09 1.43 1.19 1.02 0.96 1.52 1.27 0.37 0.76 0.80 0.60 1.46 1.09 1.33 1.03 0.81 0.98 1.61 1.14 1.55 1.34 0.76 0.43 1.29 1.54 1.10 0.38 0.66 1.24 0.55 1.20 1.38 1.59 0.35 0.63 0.83 0.96 0.57 0.72 0.58 0.96 1.40 1.25 0.81 1.05 0.74 0.71 1.44 1.13 1.04 1.67 0.71 1.45 1.03 1.15 0.43 0.30 1.45 0.89 1.02 1.62 0.20 0.89 1.65 0.41 0.78 1.56 1.73 0.78 0.20 1.37 1.04 1.46 1.21 1.75 1.29 0.98 1.70 1.12 0.91 0.03 1.61 1.19 1.62 1.09 0.89 0.44 1.12 1.42 1.24 0.56 0.53 1.01 1.43 0.57 0.66 1.03 1.19 0.61 1.18 0.62 1.15 1.01 0.96 0.60 1.61 0.71 1.70 1.35 0.86 1.47 1.52 0.79 0.71 0.51 1.10 0.97 1.18 1.53 0.42 0.32 1.29 1.16 0.76 1.12 1.43 1.13 1.09 0.65 1.32 0.69 0.27 0.66 0.65 1.57 1.32 1.10 0.92 1.61 1.76 1.30 1.31 1.15 0.35 1.20 1.94 1.07 0.55 0.66 0.92 0.28 0.13 0.86 0.63 0.73 0.18 1.60 1.46 0.89 1.54 1.47 0.97 0.70 1.26 0.72 0.61 1.43 0.37 0.79 0.74 0.40 1.55 0.43 0.76 0.82 1.41 0.79 0.82 0.90 0.85 1.28 1.63 0.19 1.00 1.00 1.51 0.66 1.42 1.08 1.41 0.47 1.18 1.19 0.74 1.09 0.72 1.05 1.07 0.34 0.23 0.81 0.75 1.80 0.57 1.34 0.78 0.78 1.06 0.95 1.05 0.39 1.40 1.10 1.69 1.55 1.78 0.65 0.84 0.69 1.33 1.38 0.82 1.06 1.12 0.68 1.04 0.93 0.51 0.93 0.47 0.11 0.82 0.77 0.22 1.06 1.48 1.66 0.59 1.19 1.71 0.88 0.95 1.20 0.83 0.65 0.60 0.54 0.54 1.09 0.77 1.32 1.59 0.57 1.67 1.88 0.63 1.14 0.55 1.04 0.47 0.68 1.47 1.47 0.55 0.76 0.71 0.58 1.05 1.48 0.91 1.11 1.11 0.13 1.60 1.05 0.86 0.12 0.97 1.32 0.16 0.83 0.17 1.18 0.56 0.94 0.01 1.02 0.30 1.80 0.32 0.96 1.58 0.50 0.68 1.06 0.91 0.72 1.30 0.28 1.55 1.32 1.27 1.69 1.47 1.46 0.32 0.97 0.50 0.44 1.29 1.01 0.37 1.27 1.62 1.53 0.78 0.72 1.16 0.63 0.88 0.44 0.50 1.08 1.86 1.17 1.01 1.35 0.90 1.05 1.19 0.68 1.42 1.03 0.79 1.23 0.74 0.86 1.06 1.24 0.47 1.08 1.58 0.86 1.07 0.99 0.49 1.24 1.06 0.49 0.93 0.52 1.37 0.91 0.32 1.36 0.55 1.25 0.88 0.61 1.02 1.21 1.26 1.41 0.73 1.18 0.62 1.32 1.08 0.42 0.38 1.18 1.22 1.06 1.53 1.05 0.26 1.05 1.71 0.85 0.36 1.09 0.72 \n",
            "0.95 0.64 1.20 1.15 0.95 0.80 1.47 0.67 0.87 0.78 0.46 1.38 0.93 0.33 1.70 0.43 0.86 1.03 1.10 1.43 0.54 1.05 0.56 0.53 0.65 1.36 0.79 1.42 1.48 0.75 0.80 1.83 1.26 0.71 1.03 0.42 0.36 0.59 1.21 1.36 0.42 0.98 1.47 0.94 1.14 0.13 1.87 1.61 0.81 0.50 0.46 1.42 0.38 1.75 1.13 1.45 0.84 0.78 1.82 1.25 1.41 0.91 1.33 0.41 0.83 0.98 0.80 1.09 1.41 0.77 0.95 1.10 1.64 1.08 0.61 0.43 1.71 1.30 0.85 0.18 1.60 0.94 1.56 0.60 0.87 1.52 0.58 0.60 1.50 0.69 1.02 1.13 0.44 0.77 1.14 0.95 1.12 0.15 0.93 0.66 1.12 1.61 0.80 0.93 0.90 0.42 1.72 0.64 0.97 1.46 0.36 0.85 1.31 1.15 0.74 1.02 1.00 0.56 0.85 0.11 1.09 0.66 1.07 1.00 0.70 1.15 0.88 0.54 1.01 1.41 0.52 1.63 1.07 1.32 0.66 0.66 0.95 1.59 0.61 1.06 1.05 1.39 0.23 1.08 0.64 1.01 0.92 1.69 0.82 0.90 1.44 1.24 0.86 0.42 0.41 0.80 1.71 0.36 1.13 1.18 0.94 0.93 1.82 0.84 0.63 1.11 1.29 1.47 1.18 0.64 0.37 1.04 0.63 1.02 0.86 0.52 0.40 0.65 1.07 0.87 0.23 1.78 1.34 0.67 1.13 1.11 0.74 0.58 0.56 1.13 0.81 1.21 1.10 0.44 1.34 0.88 1.30 1.08 0.91 1.16 1.05 0.54 1.42 1.16 0.73 1.39 0.93 0.75 1.45 1.20 0.51 1.36 0.75 1.43 0.19 0.70 0.86 1.03 1.38 1.27 0.48 0.63 1.25 0.44 1.58 1.50 0.74 0.89 0.30 0.16 0.92 0.73 1.10 0.07 0.96 1.57 0.99 1.84 0.59 1.94 0.93 1.26 0.29 1.17 0.47 1.09 1.18 1.18 0.59 1.76 1.58 0.98 0.54 0.82 1.12 1.31 0.21 0.73 0.72 1.10 1.22 0.59 1.02 0.68 1.01 1.15 1.78 1.17 0.97 0.45 0.76 0.13 1.34 0.46 1.75 1.24 0.76 1.37 1.58 1.38 1.51 1.18 1.66 0.62 1.34 0.70 0.83 1.06 1.69 1.21 1.10 0.41 1.26 0.64 0.85 1.44 0.54 0.66 0.97 0.81 1.34 1.42 1.33 1.34 1.02 0.46 1.01 0.97 1.66 1.12 0.61 0.87 1.16 1.34 0.79 1.46 1.65 1.31 1.37 1.02 1.22 0.49 0.34 0.50 1.08 0.51 1.16 0.85 0.90 1.46 1.33 0.83 0.79 0.99 0.80 0.54 1.48 1.24 1.52 0.83 1.35 1.29 0.72 0.84 0.31 0.32 1.21 0.64 1.27 1.17 0.64 1.08 0.75 0.95 1.05 1.86 1.13 0.92 1.28 1.46 1.06 1.25 0.92 1.28 1.53 1.26 1.15 1.28 0.64 1.16 1.02 1.10 1.18 1.00 0.78 1.06 0.25 1.11 1.21 1.36 1.84 0.89 0.95 1.89 1.41 1.29 1.09 1.58 1.42 0.73 1.05 1.04 0.12 0.47 1.54 1.06 1.44 0.37 0.13 0.98 1.32 0.97 0.66 0.68 1.13 1.27 1.20 1.49 1.45 0.65 0.79 0.35 0.65 0.61 0.98 0.32 0.86 0.70 0.84 1.59 0.78 1.16 0.16 1.29 1.60 0.59 0.64 0.61 0.67 1.07 0.81 0.94 0.68 1.18 1.02 1.50 1.63 1.77 1.30 1.41 1.00 0.29 0.95 0.92 0.13 1.27 1.38 0.60 1.84 1.59 0.55 1.66 0.74 0.97 1.50 0.94 1.38 1.13 1.14 0.93 1.04 1.20 0.40 0.49 0.58 1.10 1.15 1.31 1.20 0.93 1.66 1.18 1.10 0.36 1.34 1.50 1.49 1.80 0.50 1.14 1.36 1.20 1.01 1.40 0.78 0.88 1.19 0.47 0.36 0.54 1.12 1.09 0.75 0.50 0.17 1.33 0.87 1.03 1.03 1.08 0.76 1.26 1.02 1.25 0.57 1.08 1.85 0.31 1.05 0.84 1.44 0.75 1.69 0.19 1.21 1.54 0.23 0.91 1.54 0.62 0.96 1.82 0.87 0.40 0.93 1.14 0.43 0.69 0.67 0.85 1.15 0.84 0.20 0.62 0.92 0.88 0.95 1.69 1.82 0.73 0.35 1.13 0.76 0.90 1.71 0.31 1.15 1.23 0.91 1.11 1.09 0.71 0.68 0.85 1.50 0.27 1.46 0.62 0.23 0.65 1.26 0.80 0.11 1.77 0.87 0.85 0.86 0.99 0.97 1.05 1.43 1.31 0.72 1.11 0.45 0.89 0.71 1.13 0.72 0.83 0.77 0.55 0.22 1.17 1.37 0.66 0.52 1.69 0.90 1.19 0.57 0.06 0.78 1.09 0.08 1.09 1.59 1.47 0.16 1.00 0.85 1.34 1.62 0.61 0.84 0.85 0.89 1.68 1.10 1.18 0.68 1.01 0.90 1.08 1.13 1.59 0.73 0.34 0.98 0.84 0.75 1.22 1.61 1.32 0.66 0.88 0.76 1.62 1.38 0.71 1.79 0.48 1.26 0.85 0.76 1.04 1.40 1.16 1.15 1.71 0.97 1.16 0.47 1.40 1.50 1.35 1.42 1.79 1.65 0.90 0.34 0.92 1.20 0.75 0.56 0.16 1.04 1.28 1.12 1.38 0.78 0.89 0.57 0.88 1.31 1.62 1.72 1.39 0.62 1.27 1.60 0.72 0.76 1.17 0.65 0.50 0.28 0.64 1.07 0.06 1.30 1.03 1.21 0.93 1.56 1.02 0.64 0.80 0.71 1.29 1.52 1.81 1.17 0.65 0.96 0.63 0.39 1.27 1.09 1.45 0.42 0.81 1.19 1.45 0.57 1.29 0.53 0.88 1.53 0.94 0.25 0.75 1.24 0.25 0.23 0.98 1.17 1.69 1.40 1.27 0.89 1.06 0.64 1.12 0.48 0.67 0.64 1.38 0.44 1.21 0.35 1.31 0.98 0.86 1.15 1.35 0.69 0.45 1.36 0.51 0.63 1.57 1.61 0.16 1.59 1.72 1.57 0.44 1.04 0.94 0.43 1.23 1.70 1.45 1.26 0.89 0.14 1.18 1.41 1.79 0.72 0.93 0.55 0.84 1.67 1.78 1.08 0.23 1.69 0.84 1.64 1.84 1.20 1.52 1.36 1.61 0.83 1.36 1.92 0.96 0.99 0.69 1.76 0.84 1.60 1.40 1.42 1.02 0.28 1.23 0.87 1.72 1.39 1.08 1.30 0.89 1.80 1.35 1.49 1.00 0.88 0.34 0.65 0.92 0.91 0.57 0.99 1.47 1.37 0.68 0.60 0.95 0.15 0.95 1.50 0.73 1.37 0.68 1.42 0.95 0.73 1.11 1.80 1.10 1.14 0.83 0.35 1.14 1.09 1.13 1.04 0.96 0.93 1.43 1.23 0.69 1.88 1.70 1.38 0.85 1.59 0.26 1.47 1.44 1.49 1.14 0.44 0.94 0.74 1.73 0.73 0.93 1.20 1.30 0.43 1.09 1.85 0.96 1.74 0.87 0.98 1.76 1.11 0.80 1.05 0.82 0.92 0.42 0.38 0.69 0.88 0.82 1.13 1.04 1.19 1.09 0.91 0.59 1.54 0.87 0.90 0.40 1.45 0.95 0.54 0.64 1.43 1.14 1.26 0.42 1.08 1.62 0.36 1.02 1.59 0.51 0.59 1.31 0.72 0.86 0.91 1.67 0.98 0.89 0.98 1.68 0.83 1.05 1.51 1.09 0.97 0.59 0.50 0.59 0.18 0.46 0.96 0.41 0.95 0.17 1.62 1.98 1.16 0.64 1.10 1.77 0.33 0.62 1.27 1.04 1.67 1.53 1.65 0.58 0.24 1.53 1.62 1.31 0.54 1.45 1.68 0.71 1.58 0.84 0.55 1.30 1.40 0.86 0.76 0.65 1.22 0.86 0.68 1.63 1.12 0.86 1.30 0.81 0.91 0.74 0.54 1.67 1.87 0.99 1.00 1.63 0.80 1.07 0.66 0.70 0.77 0.57 1.14 0.95 1.05 1.49 0.72 0.53 0.71 1.21 1.14 0.93 1.31 0.42 1.70 0.74 1.67 1.53 1.70 0.85 1.16 1.33 0.52 1.46 1.37 0.95 0.49 1.47 1.90 1.76 0.99 1.04 1.82 1.48 1.04 0.27 1.68 1.09 1.47 0.44 1.21 1.37 1.30 1.50 0.71 0.77 0.78 1.37 1.39 1.12 1.19 1.65 1.00 1.08 1.28 1.32 0.92 1.18 1.52 1.42 0.95 0.92 1.01 1.32 1.15 0.85 0.84 1.20 1.22 0.32 0.80 0.97 1.33 0.96 0.84 0.07 1.57 0.52 0.29 0.98 0.30 1.79 0.31 0.99 1.27 1.01 0.95 0.80 1.13 1.13 1.14 0.77 1.21 1.28 1.14 0.94 1.08 0.58 1.72 0.91 0.88 1.06 0.90 1.12 0.62 1.01 1.46 0.47 1.06 0.16 1.01 0.63 0.82 0.46 0.77 1.53 1.29 0.48 1.45 1.24 0.86 0.85 1.03 0.97 1.06 0.29 1.23 1.15 1.13 0.60 0.99 0.55 0.73 1.48 0.64 1.26 0.97 0.81 1.42 1.09 0.91 0.55 1.30 0.20 0.31 1.32 0.93 1.58 0.91 1.83 0.76 1.03 1.19 0.73 0.62 1.11 1.20 0.66 0.35 0.92 0.65 0.95 1.12 1.23 1.57 0.56 0.14 1.08 1.42 0.96 0.64 1.55 1.72 1.34 1.06 0.72 0.51 1.30 1.19 0.64 0.58 1.11 0.78 1.07 1.00 0.23 1.10 0.47 0.98 0.88 1.08 1.76 1.27 1.21 1.56 0.22 1.05 0.87 0.51 1.01 0.98 1.13 1.01 0.89 0.43 1.02 1.37 1.09 1.83 1.09 1.17 1.54 0.64 1.05 1.36 0.64 1.30 0.41 0.38 0.29 1.07 1.31 1.11 1.07 0.72 1.33 0.47 1.11 1.29 1.26 1.22 0.98 1.68 0.83 1.68 0.87 0.46 1.18 0.58 0.49 1.41 1.19 1.70 1.01 1.46 0.63 1.16 1.21 1.00 0.91 1.17 1.43 0.96 1.18 0.86 1.84 0.51 1.18 1.33 1.19 0.45 1.47 1.43 0.46 0.72 1.11 1.15 1.50 1.15 0.65 1.36 1.30 0.51 0.08 1.66 0.63 1.09 1.73 0.78 0.96 1.56 0.39 0.61 0.82 1.57 0.76 0.95 1.81 1.54 1.30 1.16 1.32 1.03 0.77 1.24 0.30 0.80 0.51 0.57 0.15 0.79 1.08 0.98 1.21 0.78 1.72 0.45 1.18 1.08 1.29 1.68 1.10 0.27 0.87 0.93 0.99 0.94 0.48 0.98 1.44 1.20 1.69 1.19 1.13 0.82 0.58 1.01 0.96 0.28 1.14 0.85 1.94 1.22 0.72 1.10 0.95 1.31 0.96 1.52 0.77 1.51 0.84 1.03 0.81 1.64 0.52 0.08 1.28 0.87 1.49 0.13 1.28 1.09 0.95 0.34 0.95 1.06 0.37 0.58 1.40 1.13 0.69 1.38 0.50 0.97 0.22 1.44 0.55 0.75 1.14 1.22 0.94 1.86 1.37 0.48 1.65 1.68 0.81 1.32 1.30 1.30 1.40 1.02 0.27 1.44 0.85 0.48 0.93 0.08 0.79 0.06 1.17 1.77 0.81 1.29 0.39 0.64 1.34 1.73 1.43 1.00 1.84 1.06 0.83 1.07 0.72 1.04 0.88 0.88 0.92 0.80 1.77 1.09 1.09 0.71 1.00 1.80 1.19 0.60 1.02 0.62 0.81 0.64 1.48 1.38 0.70 0.71 1.62 0.58 0.62 1.24 1.00 0.46 0.91 1.20 1.73 0.68 1.48 1.23 0.84 0.35 0.79 1.01 0.86 1.12 0.87 1.10 1.40 1.05 1.61 1.24 1.06 0.89 0.23 1.48 0.73 1.62 0.89 0.93 0.21 1.22 1.40 0.94 0.88 1.12 0.24 0.84 1.26 0.83 0.85 0.58 1.14 1.08 0.82 0.77 1.05 1.10 1.33 1.27 1.03 1.70 0.73 0.57 1.28 1.50 0.70 1.70 0.28 0.88 0.80 1.11 0.65 1.32 1.24 1.17 0.96 1.53 0.44 1.68 1.50 0.84 1.26 1.05 1.33 0.63 1.58 0.97 0.93 1.21 0.86 1.43 1.26 0.51 1.06 0.42 1.37 0.76 0.80 1.17 0.74 1.25 0.54 0.55 1.51 0.63 1.14 1.20 1.03 1.12 0.89 0.64 0.78 0.90 1.22 0.71 0.87 1.29 1.20 0.87 0.59 0.09 1.57 1.15 0.99 0.69 0.79 1.14 0.74 1.15 1.12 0.92 0.84 1.40 1.05 0.75 0.79 0.38 1.11 0.96 1.80 0.97 0.97 1.15 0.15 0.68 1.18 0.27 1.82 1.06 0.95 1.51 1.64 0.11 1.43 0.82 0.71 0.81 0.90 1.39 1.27 0.33 0.68 0.46 0.28 1.36 1.32 0.97 1.76 0.69 1.13 0.42 1.30 0.52 0.19 1.25 0.99 0.90 1.19 1.16 0.88 0.68 0.38 1.16 0.72 1.34 1.36 0.70 0.98 0.87 1.13 1.63 0.71 0.78 0.89 0.34 1.45 0.98 0.67 0.98 0.99 1.27 1.07 1.02 1.18 0.22 1.00 1.42 0.39 0.60 1.14 1.06 0.96 0.44 1.20 1.04 1.73 0.54 1.27 1.85 1.45 0.75 0.92 0.17 0.37 1.60 0.71 1.10 0.71 1.32 0.95 1.09 0.66 0.49 1.21 0.37 0.42 0.12 0.29 0.65 1.07 1.18 0.90 0.45 0.82 0.52 1.13 0.46 1.27 0.71 0.30 1.14 1.20 1.04 1.55 0.16 0.93 1.39 0.61 1.45 0.60 1.21 0.59 0.51 1.63 1.33 0.31 0.63 0.72 1.01 0.34 0.89 0.49 1.10 1.12 1.54 1.52 0.45 1.42 0.95 1.20 0.97 0.75 1.03 1.26 0.75 1.20 0.87 0.93 0.81 1.53 0.78 1.10 1.15 0.19 0.57 1.38 1.89 1.12 0.60 0.95 0.97 0.99 0.86 0.83 0.98 1.01 0.40 0.97 0.62 0.65 1.55 0.72 1.17 1.37 1.22 0.12 0.47 1.04 0.04 0.99 1.24 0.77 1.11 0.19 0.92 0.93 0.88 1.90 0.48 1.80 1.59 0.89 1.04 0.39 1.81 1.09 0.39 1.68 1.61 1.24 0.71 0.99 0.80 0.62 1.16 0.98 0.34 0.80 0.81 1.45 1.57 0.65 1.41 1.47 1.20 1.54 0.87 1.49 0.43 0.95 0.54 1.33 0.81 1.25 0.32 1.24 0.23 0.85 1.22 1.66 1.03 1.33 0.74 0.56 0.94 0.77 0.47 1.35 1.22 0.91 1.28 1.43 1.04 1.15 0.60 0.69 1.03 0.52 0.86 0.94 0.61 1.27 0.81 0.35 1.21 1.57 1.42 1.00 1.28 1.73 0.95 0.50 1.46 0.75 0.10 1.11 0.41 0.78 1.01 1.24 1.40 0.70 0.81 0.26 1.83 0.97 1.41 1.76 0.49 0.18 1.20 1.29 1.69 0.82 0.19 0.92 0.88 1.39 1.32 0.79 0.64 0.93 1.23 0.91 1.19 1.30 1.39 1.01 0.65 0.79 0.89 0.42 1.33 0.46 0.47 0.80 1.01 0.15 0.43 0.96 1.15 1.02 0.84 0.62 0.85 1.32 1.12 1.49 1.55 1.11 0.20 1.12 1.65 0.47 0.33 0.70 1.68 1.01 0.74 1.01 1.04 0.32 1.07 1.61 1.78 1.65 0.64 1.20 1.04 1.36 1.09 1.84 1.79 1.30 0.48 1.12 0.63 0.67 0.26 0.32 1.01 1.00 0.74 0.93 1.87 1.15 0.36 1.74 0.84 0.67 1.34 0.83 1.23 1.67 0.80 1.50 0.96 1.46 1.70 1.48 1.68 1.54 0.62 1.19 0.32 0.78 0.65 0.63 1.13 1.35 1.30 0.74 1.36 0.96 0.58 0.64 0.07 0.30 1.46 1.15 0.35 1.43 0.56 0.87 1.37 0.63 1.08 0.93 0.56 1.50 0.33 0.40 0.33 1.09 0.19 0.56 1.18 0.54 1.06 1.43 0.64 1.09 1.43 1.15 0.90 1.12 1.80 0.62 0.22 0.90 0.96 0.94 1.45 0.88 0.90 0.92 1.37 0.25 1.03 0.78 1.07 0.16 1.41 0.97 1.51 1.04 1.32 0.61 0.47 1.27 0.81 0.91 0.22 0.97 0.58 1.18 0.63 1.49 1.13 0.68 1.33 1.11 0.70 1.42 1.21 1.53 0.89 1.20 1.61 0.35 0.89 0.83 0.87 1.58 0.77 1.64 0.96 0.76 1.45 0.81 0.88 1.68 0.79 0.88 1.03 1.58 0.76 1.46 0.72 0.63 0.29 0.59 0.99 0.91 1.54 1.10 1.06 1.19 0.65 0.25 1.31 1.62 1.23 0.70 1.12 1.43 1.58 0.66 0.38 1.01 0.28 1.33 1.90 1.20 1.59 1.25 1.28 0.96 0.94 0.45 0.98 1.46 1.90 1.14 0.68 1.19 1.27 1.30 1.05 0.73 0.96 0.54 0.84 0.75 1.16 0.83 1.08 1.70 0.42 1.27 0.98 0.05 0.98 1.43 0.87 0.67 1.13 1.07 0.72 0.73 1.02 1.02 0.85 1.09 0.55 0.36 0.82 0.79 0.77 0.85 0.38 1.47 0.74 0.48 0.36 0.33 0.77 1.48 1.07 0.90 0.93 1.16 0.67 0.57 1.18 1.07 1.93 1.08 1.08 1.13 1.78 0.82 0.81 1.19 0.87 1.51 0.35 0.56 1.64 0.44 1.52 1.40 1.07 1.12 1.05 0.58 0.69 0.39 0.69 0.40 0.67 1.37 0.58 1.01 1.04 1.06 0.98 1.01 0.94 1.19 1.36 0.83 0.18 0.55 0.80 1.44 0.86 1.48 0.72 0.68 0.96 0.31 1.20 1.00 1.44 1.14 0.98 0.83 1.19 1.04 1.33 0.47 1.29 0.63 1.45 0.77 1.04 0.36 0.39 0.37 1.57 0.62 1.49 0.71 0.84 0.67 1.23 1.36 1.10 1.53 1.30 0.96 0.38 0.57 0.68 1.60 0.46 0.79 0.68 0.63 1.25 1.69 1.45 1.00 1.04 1.09 0.83 1.68 1.36 0.97 1.21 1.29 0.81 0.63 0.58 1.00 1.55 1.32 0.74 0.56 0.85 1.14 1.68 0.89 1.09 1.08 1.45 0.98 0.43 0.74 0.85 0.85 0.44 1.41 1.50 0.97 0.61 1.04 0.92 0.33 1.79 1.31 0.77 1.51 0.89 1.23 1.00 1.15 1.25 0.61 0.53 1.10 0.69 1.43 0.06 1.63 1.17 1.09 1.24 1.16 1.85 0.86 0.46 1.28 0.58 1.47 0.48 1.25 0.70 0.78 0.44 0.61 0.36 1.57 1.30 0.72 1.12 0.99 1.59 0.30 0.17 1.28 0.34 0.81 1.20 1.78 1.00 0.27 1.09 0.94 0.57 1.53 1.25 1.26 0.81 1.01 0.34 0.63 0.82 1.70 1.02 1.68 0.88 0.37 0.79 0.36 0.98 1.04 0.43 1.06 0.87 1.22 1.37 0.89 1.26 1.20 1.09 1.29 0.83 0.94 0.97 0.97 0.21 1.17 0.30 0.88 1.30 0.39 0.94 1.85 0.86 0.49 0.93 0.93 1.45 0.37 0.18 0.37 0.34 1.03 0.76 0.80 1.01 0.72 1.46 0.17 0.63 0.28 1.46 0.33 1.09 1.33 1.05 0.65 1.23 1.02 0.59 1.05 1.01 1.56 1.34 0.78 0.38 1.55 0.28 1.75 0.58 1.62 1.76 1.02 0.95 0.98 0.85 1.14 1.78 1.32 1.41 1.10 1.17 0.63 0.52 0.81 0.45 0.74 1.69 1.20 0.79 1.18 1.19 0.50 1.02 1.11 1.92 1.23 0.87 0.54 1.25 0.50 0.78 0.91 0.99 1.12 0.30 0.42 0.62 0.48 0.75 1.07 0.80 0.77 1.17 1.06 1.66 1.11 0.78 0.90 1.15 0.56 0.32 0.95 0.91 0.59 1.01 1.33 0.96 1.48 0.40 0.54 1.08 0.49 1.68 0.64 1.43 1.28 1.20 0.70 0.66 0.77 1.94 0.49 1.20 1.02 1.50 1.65 1.20 1.45 0.54 1.71 0.31 0.71 1.23 1.63 1.70 1.57 1.50 0.53 1.03 1.30 1.09 0.13 1.10 1.17 0.68 0.61 0.86 0.51 1.73 0.97 1.54 1.06 1.60 0.73 1.13 1.17 0.98 1.51 0.87 0.73 0.55 1.57 0.65 0.49 1.22 0.81 0.99 0.78 1.46 1.22 0.53 0.81 1.67 0.61 1.01 1.10 0.66 0.96 0.75 0.70 0.92 0.71 0.37 0.51 1.00 1.43 1.10 1.07 0.57 1.31 1.00 1.12 1.09 0.97 1.54 0.81 1.17 1.38 1.02 1.38 0.61 1.58 1.05 0.47 1.31 1.18 0.20 0.98 1.39 0.14 1.62 0.40 1.48 1.35 0.67 0.55 1.53 0.99 0.77 1.20 1.25 1.39 1.70 0.74 1.32 1.03 0.83 1.73 1.22 0.82 0.81 1.17 0.49 0.92 0.63 1.34 0.51 1.33 1.10 0.30 0.95 1.37 0.76 1.10 1.18 0.87 0.29 1.34 1.21 1.04 0.38 0.71 1.12 1.11 1.12 1.64 0.74 0.86 1.11 1.49 0.88 0.29 0.40 0.95 0.88 0.45 1.37 1.17 0.22 0.70 1.68 1.41 1.34 0.93 1.22 0.74 0.77 1.27 0.65 0.78 1.21 1.80 1.40 1.06 1.24 0.96 1.09 1.36 1.65 0.88 0.70 0.97 1.65 0.64 1.46 1.83 1.66 1.25 0.60 0.70 1.06 0.78 1.04 0.58 1.43 1.55 1.07 1.60 1.76 1.02 0.66 0.89 0.49 1.39 0.46 0.93 0.74 0.66 0.86 0.46 1.70 0.42 1.53 0.49 1.25 0.52 1.36 1.24 0.57 0.93 0.72 0.53 0.59 0.23 0.45 0.74 1.69 0.92 1.18 1.51 0.91 1.36 1.44 0.13 1.22 1.04 0.93 0.38 0.78 0.96 1.29 1.37 0.86 1.19 1.69 1.47 1.73 0.89 0.41 1.19 1.08 0.56 1.81 0.52 0.57 0.81 0.20 0.83 0.45 1.10 1.72 1.76 1.40 1.64 1.66 0.45 1.06 0.74 0.98 1.44 1.77 0.40 1.42 1.03 1.25 1.02 0.72 1.44 0.41 0.94 1.90 0.80 1.42 0.83 0.81 0.94 0.52 0.54 1.56 0.81 0.71 0.80 0.60 0.55 1.32 1.08 0.90 1.20 1.43 0.71 0.30 0.81 0.98 0.76 0.93 0.37 1.40 1.06 0.41 1.02 0.11 0.97 0.99 0.31 1.19 0.66 0.68 1.32 0.82 1.22 1.66 1.39 0.76 1.07 1.06 0.92 1.20 1.17 1.05 1.61 0.51 0.74 0.73 1.86 1.15 1.31 0.66 0.87 1.14 0.60 1.04 1.37 1.41 1.43 1.03 0.71 1.30 0.74 1.52 1.59 0.68 0.49 0.58 1.78 1.30 1.92 0.91 1.57 0.84 0.79 1.05 0.41 0.96 0.39 0.75 1.17 1.88 0.79 1.02 1.19 0.95 0.67 1.40 1.18 1.25 0.11 0.47 0.65 0.67 0.91 1.03 0.86 0.75 1.36 1.21 1.10 1.64 1.02 1.01 0.28 0.18 0.55 0.92 1.08 0.23 1.03 1.09 1.15 1.54 1.60 1.05 0.93 0.47 0.75 1.16 0.74 1.43 0.99 0.49 0.94 1.08 0.99 0.86 1.00 0.65 1.16 1.32 1.41 1.03 1.28 1.19 1.53 1.32 0.96 1.60 0.55 0.89 1.83 1.67 0.15 0.44 1.04 1.39 1.55 1.62 1.62 0.85 1.42 0.67 0.98 0.29 0.94 1.05 0.93 0.60 1.06 1.39 0.80 0.57 0.20 0.18 0.99 0.96 1.20 0.78 0.89 0.70 1.27 1.60 0.48 0.27 1.25 1.65 0.43 0.41 0.40 1.45 0.62 0.80 1.03 0.98 1.67 0.73 1.42 1.12 1.53 0.43 1.06 0.84 1.30 1.12 1.84 1.10 0.98 1.28 1.48 0.91 0.93 1.07 0.98 1.25 0.59 1.29 0.77 0.13 1.38 1.79 0.84 0.68 0.79 0.83 0.21 1.40 0.39 0.51 0.66 0.88 1.45 0.89 1.30 1.30 1.29 0.88 0.97 0.96 0.52 1.01 0.53 0.88 0.86 1.31 1.14 0.76 1.36 0.80 1.68 1.33 0.19 0.11 0.78 0.93 0.86 1.02 0.35 1.32 1.28 0.72 0.80 1.00 1.14 0.83 0.91 0.79 1.38 1.28 0.97 0.48 1.14 0.22 1.40 0.71 1.16 1.10 0.92 1.13 0.90 0.87 1.12 0.92 1.56 0.67 1.39 0.36 0.64 1.04 1.11 1.74 1.17 0.23 1.94 1.15 0.32 1.66 0.69 0.93 0.77 0.78 1.74 0.72 0.71 0.44 0.48 1.09 1.01 0.75 0.68 0.80 0.92 0.43 1.05 0.84 0.95 1.00 0.75 1.08 0.46 1.30 0.70 1.60 1.72 0.67 1.24 1.41 0.94 0.76 1.19 0.82 0.21 0.83 1.54 0.43 1.44 0.94 1.12 0.86 0.88 1.24 0.99 1.28 1.49 0.92 1.64 1.82 1.55 0.82 0.57 1.08 0.97 1.15 1.55 0.92 1.52 0.55 0.83 1.44 0.87 1.00 1.10 0.36 0.47 0.73 0.43 1.04 0.83 0.49 1.19 0.80 0.59 1.22 1.19 1.74 1.02 1.57 0.56 1.76 1.13 1.07 0.32 0.95 0.29 0.52 0.86 1.18 1.67 0.87 1.06 0.93 0.35 1.21 0.43 0.94 0.47 1.11 1.11 0.93 1.50 0.87 0.78 0.81 0.46 1.32 1.28 1.61 0.73 1.53 0.78 0.72 1.48 1.05 0.88 0.99 1.44 0.75 0.91 0.68 0.22 1.89 1.24 1.14 1.30 0.14 0.15 1.33 0.68 1.22 0.36 0.95 1.05 1.02 1.26 1.33 1.69 0.99 0.71 0.91 1.79 1.08 0.91 0.56 0.79 1.16 0.97 0.94 0.81 0.99 1.66 1.56 0.54 1.28 0.67 1.26 0.24 0.38 1.75 0.74 1.71 0.69 1.01 1.70 1.60 0.89 1.02 1.60 0.98 0.81 1.07 1.11 1.40 1.46 1.43 0.69 1.10 1.81 1.01 0.93 1.21 0.85 1.27 0.79 0.33 0.90 1.66 0.72 1.49 1.20 1.39 1.06 1.26 0.60 0.40 0.87 0.35 0.84 1.17 0.88 1.24 0.91 0.80 0.95 1.81 1.22 1.03 0.70 0.15 0.56 0.82 1.14 1.15 0.80 0.61 0.82 0.47 0.74 0.35 0.56 0.83 0.37 1.05 1.15 1.35 1.73 1.13 0.36 0.86 0.58 0.84 1.31 1.12 1.57 0.72 1.63 0.90 1.40 1.07 0.14 1.25 1.61 0.75 1.65 1.12 1.08 1.62 1.28 0.42 1.21 0.99 0.67 0.85 0.85 1.62 0.34 0.87 1.24 0.90 0.23 1.13 1.00 1.68 1.49 0.13 1.23 1.55 1.01 0.97 0.31 0.85 0.45 0.60 1.34 1.59 1.53 1.88 1.46 0.80 1.67 0.66 1.06 0.79 1.61 1.94 1.34 0.58 1.50 0.48 0.66 0.40 1.79 0.71 0.84 1.21 1.45 0.40 1.09 0.59 0.96 0.62 1.31 1.07 1.37 0.65 1.64 1.22 1.34 0.69 1.45 0.70 0.79 1.42 0.30 1.57 1.54 0.55 1.38 1.66 1.19 1.78 0.36 1.27 0.93 0.89 0.86 1.29 0.70 1.52 0.72 1.25 1.28 0.10 1.42 1.41 1.07 0.44 1.18 1.14 1.66 0.50 0.62 1.16 0.50 1.31 0.76 0.46 1.36 0.70 0.32 0.39 0.29 0.82 0.53 1.59 1.00 0.71 0.88 0.93 1.55 0.58 0.80 0.36 0.59 0.93 1.15 1.30 1.15 0.92 1.09 0.87 0.61 0.71 0.44 0.87 0.88 1.31 0.49 0.84 0.71 1.00 1.09 1.31 1.42 0.92 0.74 0.61 1.36 1.84 0.96 0.81 1.15 1.52 0.78 0.73 0.12 1.36 1.02 0.46 0.89 0.95 1.16 0.98 0.88 0.34 1.52 0.68 1.25 0.31 1.56 0.53 0.76 0.89 1.56 1.21 0.72 1.08 1.72 0.40 0.86 0.44 0.88 1.04 1.33 1.17 0.39 1.57 0.59 0.92 0.81 1.60 1.29 1.41 0.73 1.62 1.55 0.96 1.19 0.54 1.36 1.41 0.41 0.89 1.43 0.14 0.94 0.78 1.41 0.25 1.00 1.72 0.92 0.97 1.69 0.62 1.22 0.79 1.01 0.63 0.49 0.69 0.52 0.65 0.66 1.05 0.75 1.19 1.46 0.78 1.67 1.19 0.43 1.52 0.64 0.89 0.93 0.55 1.05 0.37 1.09 1.36 1.20 1.50 1.70 0.81 1.68 0.25 0.97 1.56 0.93 0.75 1.03 1.30 1.50 0.78 1.10 1.43 0.67 0.96 0.21 0.74 1.76 1.00 1.76 1.34 0.99 0.54 1.39 1.09 1.51 0.47 1.00 0.92 1.83 1.04 1.65 0.93 0.76 1.13 0.47 0.20 0.56 1.47 0.58 0.83 0.42 0.73 1.20 1.08 0.53 1.08 1.90 0.59 0.92 1.17 0.18 0.84 1.11 0.68 0.86 0.80 0.80 0.69 1.18 1.03 0.89 0.89 1.12 0.43 1.18 0.42 0.99 1.10 1.57 0.81 1.28 1.69 0.14 1.08 1.15 1.03 1.22 0.82 1.40 1.37 0.87 0.94 1.06 0.96 0.81 1.06 0.37 1.17 0.13 0.85 1.36 0.32 0.81 0.92 0.39 1.78 1.10 0.12 0.76 0.79 0.83 0.66 1.59 1.73 1.08 1.01 1.46 1.02 1.46 0.47 1.25 1.12 0.99 0.50 1.33 1.32 1.13 0.36 0.82 1.45 0.67 0.32 1.78 1.40 1.30 1.11 1.15 0.88 1.48 0.88 0.67 0.97 1.18 0.52 1.43 0.89 0.42 0.23 0.57 0.44 0.52 1.41 1.77 0.80 1.69 1.06 0.89 1.16 0.36 1.07 0.65 0.89 1.17 1.27 0.76 0.60 1.24 0.94 1.31 1.27 1.42 1.36 1.36 1.38 0.21 0.51 1.41 0.93 0.53 1.31 1.90 1.56 0.94 0.15 0.26 1.25 1.75 0.98 1.13 0.84 0.80 0.20 0.77 0.79 1.32 1.58 1.02 1.35 0.66 1.20 0.91 0.59 1.05 0.78 0.94 1.53 0.98 0.94 0.85 1.04 0.83 1.39 1.77 1.82 1.23 0.34 0.48 0.82 0.51 0.71 0.23 0.17 0.96 0.95 0.85 0.99 1.60 1.53 1.10 0.80 0.37 0.50 1.07 1.38 0.92 1.02 0.33 0.35 0.31 1.11 0.28 1.84 1.47 1.25 0.72 0.92 1.18 0.93 0.73 0.82 1.41 0.81 1.03 1.05 0.46 0.50 1.24 0.63 0.71 1.28 0.92 0.52 1.61 1.34 0.77 1.00 1.00 0.92 1.97 1.37 0.11 1.18 1.21 1.08 0.69 0.35 0.56 0.72 0.32 1.52 1.24 1.27 1.32 1.26 1.15 0.72 1.51 0.63 0.71 0.62 1.07 1.03 0.82 0.80 0.83 0.24 1.83 1.29 0.70 0.43 1.19 1.12 1.05 0.41 0.48 1.16 0.99 1.18 0.95 0.96 1.30 1.83 0.70 1.26 1.68 1.26 0.82 1.58 1.15 0.61 1.01 1.17 0.98 0.81 0.34 0.70 0.96 0.74 1.67 1.06 0.67 1.23 0.70 1.36 0.80 0.47 0.77 0.79 0.99 0.68 1.36 0.95 0.92 0.99 0.68 0.95 0.37 0.85 1.00 0.92 1.18 0.59 1.03 0.69 0.98 0.34 1.74 0.65 0.98 0.25 0.68 1.01 0.37 1.14 1.08 1.16 1.45 1.22 1.14 0.50 1.27 1.45 0.13 0.67 0.74 0.77 1.12 1.47 0.66 1.87 1.66 1.00 0.78 1.60 0.11 1.03 0.94 1.38 1.57 0.17 0.98 0.72 0.72 0.60 1.79 1.10 1.49 0.58 0.30 0.19 0.27 0.79 0.69 0.27 0.23 0.56 1.37 1.32 1.46 0.46 1.38 0.71 0.66 1.14 1.46 1.39 1.54 0.94 1.36 1.48 1.65 0.81 1.30 1.11 1.03 1.01 1.13 1.28 1.01 0.77 1.75 1.20 1.33 0.51 1.35 0.29 1.01 1.02 0.23 1.07 0.70 0.68 1.80 1.63 0.38 0.27 0.55 1.42 0.61 1.57 0.91 0.96 0.96 0.24 1.11 0.46 1.38 0.65 1.11 0.97 0.67 0.63 0.71 0.10 0.99 1.29 1.53 0.82 1.23 1.69 1.36 1.15 1.30 0.92 1.09 0.90 1.13 0.98 1.58 1.17 0.75 0.46 0.70 0.77 1.35 1.27 0.61 0.45 1.23 1.31 1.26 1.08 0.74 1.23 1.14 0.88 0.84 1.16 1.62 1.47 1.39 1.68 0.19 0.90 1.52 0.73 0.43 1.15 0.87 0.48 1.77 0.89 0.69 1.15 0.98 0.28 0.38 1.36 1.10 0.98 1.48 0.38 1.52 1.07 0.91 1.40 1.90 1.28 1.34 0.90 1.06 0.68 1.15 1.00 0.31 0.88 1.69 0.69 1.79 1.59 1.30 1.39 \n",
            "1.29 0.79 1.10 0.94 0.88 0.59 0.67 1.29 0.57 1.76 0.42 0.47 0.20 1.94 1.07 1.69 0.98 0.97 0.16 1.24 1.55 1.08 0.43 1.21 1.54 0.27 1.43 1.19 0.81 1.12 1.44 0.23 0.29 0.51 1.12 1.49 1.58 1.91 0.95 1.02 1.09 1.44 1.03 1.14 0.74 1.73 1.08 0.59 1.17 0.81 0.84 0.96 0.88 0.43 0.97 0.30 1.74 1.58 0.36 0.63 0.99 0.27 0.34 1.42 0.97 1.78 1.54 0.24 0.61 1.24 1.12 0.65 1.27 0.65 0.94 0.74 1.66 0.98 0.89 1.49 0.64 1.68 1.02 0.60 0.59 1.22 1.39 0.58 1.09 1.30 0.51 0.95 0.05 1.15 1.33 0.81 0.90 1.16 1.42 1.55 0.60 0.72 1.63 0.64 0.53 1.75 0.97 1.21 1.62 0.96 0.99 0.94 0.26 0.80 1.84 0.69 1.12 1.42 1.72 0.48 0.98 0.30 0.91 0.98 1.86 0.49 0.70 0.73 0.51 0.66 0.90 0.79 1.75 0.79 1.26 1.73 0.48 1.20 0.53 0.93 1.10 1.23 0.84 0.77 1.52 1.69 0.77 0.45 0.68 1.00 1.50 1.18 1.76 1.39 0.55 0.66 0.73 0.46 0.87 0.90 0.66 0.81 1.07 0.95 1.49 0.69 0.68 0.98 0.26 0.72 0.68 0.47 1.27 0.96 1.16 0.53 1.46 1.25 1.60 1.29 1.15 1.08 1.86 0.26 0.42 0.94 1.35 1.51 1.33 0.77 1.34 1.31 0.64 0.33 0.75 1.32 0.60 0.72 0.46 0.58 0.94 0.99 0.92 0.91 0.96 0.74 1.00 1.10 0.59 0.87 1.06 1.22 0.59 1.11 0.92 0.93 1.20 0.15 0.41 1.36 0.75 0.68 0.14 1.38 0.22 1.06 0.44 0.93 1.22 1.08 0.73 1.00 0.92 1.05 1.21 0.71 0.51 0.72 0.17 0.37 0.36 0.68 0.72 0.83 0.65 1.08 0.92 0.32 1.21 1.18 1.77 0.39 1.26 0.93 1.20 0.84 0.72 1.35 0.12 0.39 1.10 1.17 1.54 0.85 0.86 1.17 0.91 0.92 0.66 0.62 1.14 1.41 0.96 0.31 0.95 0.87 1.17 1.07 0.54 1.46 0.95 1.03 0.20 1.04 0.81 0.71 1.11 0.80 0.89 1.16 1.81 0.88 1.09 0.70 0.87 1.03 0.79 0.68 1.02 0.85 1.38 0.77 0.68 0.56 0.69 0.41 0.76 1.50 0.25 0.48 1.35 1.93 0.57 1.14 1.35 0.41 1.56 1.21 0.75 0.81 1.49 0.95 1.52 1.10 0.64 0.88 1.06 1.14 1.44 1.21 0.28 1.50 1.79 1.06 0.47 0.99 1.10 1.21 1.38 1.38 0.86 1.02 1.08 1.55 1.44 0.30 1.38 0.55 1.51 1.72 0.49 0.94 1.64 1.21 0.45 1.04 0.85 1.22 1.21 0.46 0.52 1.37 0.55 1.08 0.53 1.05 1.51 0.62 1.14 1.18 1.42 0.88 1.27 1.21 0.87 1.13 0.42 0.29 1.41 1.04 1.18 0.97 1.07 1.85 0.44 1.79 1.25 1.13 0.77 1.00 1.01 1.02 0.62 0.39 1.69 0.99 0.50 1.56 1.56 0.78 1.45 0.84 1.24 1.22 1.32 0.65 1.35 0.74 1.00 1.02 0.54 1.56 0.97 0.62 0.54 0.52 0.97 0.66 1.35 0.21 1.10 1.00 1.54 0.43 0.87 1.22 1.46 0.45 0.91 0.96 1.46 1.43 1.85 0.63 0.97 0.87 1.70 1.53 1.60 1.76 1.41 0.87 0.77 1.28 0.39 0.13 1.72 1.28 1.65 0.77 0.75 1.70 1.52 0.67 1.18 0.57 0.42 0.45 1.77 0.88 0.98 1.02 1.57 1.28 1.21 0.84 0.70 0.41 0.75 1.32 0.52 0.52 1.34 1.14 0.71 1.27 1.04 1.39 1.60 0.82 0.72 0.77 1.19 0.63 1.25 0.87 0.85 1.71 0.36 1.30 0.86 0.75 0.87 1.50 0.81 0.28 0.97 0.95 1.22 1.10 0.52 1.24 1.36 0.56 0.79 0.76 1.43 1.55 0.65 1.76 1.36 0.99 1.08 0.50 0.51 0.76 0.57 1.39 0.94 0.64 0.80 0.39 0.93 0.51 0.98 1.04 1.30 0.68 0.95 0.67 0.78 1.49 1.42 0.28 0.83 1.10 1.34 1.86 0.42 0.84 1.64 0.73 0.91 1.32 0.59 1.34 1.42 0.74 0.71 1.21 1.96 1.18 0.80 1.56 0.41 0.61 1.29 0.99 0.76 1.06 1.30 1.73 1.23 0.56 1.49 1.49 1.09 0.74 0.70 1.10 0.71 1.15 0.04 0.20 1.45 1.15 0.66 0.47 1.36 0.82 0.82 1.30 0.97 0.80 1.35 0.77 0.60 1.06 1.07 1.45 1.52 1.28 1.48 1.08 0.79 0.69 1.21 0.52 0.04 0.84 1.21 0.44 1.55 1.46 0.78 1.13 0.51 1.48 1.14 1.83 1.47 0.54 0.51 0.84 1.37 0.93 1.31 1.41 0.88 1.46 0.79 0.96 0.98 1.29 1.01 1.04 0.65 1.14 1.63 0.71 0.67 1.58 1.01 1.83 0.86 0.56 0.87 0.95 0.96 0.98 0.38 0.43 1.60 1.20 1.55 1.22 1.54 1.20 0.80 1.45 0.31 1.31 1.53 1.04 1.52 0.47 1.03 0.93 0.47 1.86 1.03 0.23 0.89 0.12 1.46 1.36 0.59 0.95 0.95 0.62 1.00 0.36 0.98 0.66 0.43 0.46 0.60 1.03 1.12 1.20 0.72 0.34 1.22 0.43 1.29 0.64 1.13 0.32 1.31 0.56 1.51 1.20 0.72 1.61 1.38 0.43 0.35 1.40 1.08 0.75 1.88 0.67 1.39 1.14 1.97 1.44 1.73 1.58 0.88 1.29 0.99 1.35 1.50 0.92 0.59 0.94 0.06 1.50 0.58 1.16 0.34 1.03 1.24 1.52 0.81 0.37 1.54 1.15 1.48 0.61 1.75 1.54 1.15 1.27 0.68 0.29 1.03 0.07 0.94 1.39 0.41 1.55 1.49 0.98 0.78 0.05 1.14 1.34 1.64 1.04 1.05 1.32 0.66 1.36 0.99 1.36 1.52 1.34 0.63 0.99 0.92 0.93 0.64 0.37 1.89 0.58 1.74 1.02 1.29 1.01 1.13 1.68 1.28 1.67 1.35 0.31 0.70 1.34 1.52 1.61 1.11 1.35 1.09 1.25 0.75 0.67 0.63 0.53 1.37 0.82 0.86 0.98 0.37 0.89 1.03 1.30 0.69 1.00 1.03 1.17 1.52 0.65 1.19 1.06 0.38 1.26 1.00 1.79 0.57 1.26 1.17 0.74 1.22 0.65 0.99 1.02 1.66 1.64 0.86 1.40 1.58 1.48 0.90 0.96 0.95 1.07 0.79 0.99 0.55 1.25 1.45 1.03 0.96 0.96 0.39 1.07 1.01 0.56 1.82 1.38 1.74 0.88 1.25 1.53 0.50 1.33 1.04 1.07 1.05 0.82 1.37 1.41 0.44 1.29 1.47 1.03 1.13 0.74 0.79 1.19 1.04 1.24 0.88 0.08 1.33 1.39 1.79 1.08 1.75 1.48 1.06 1.45 1.42 0.58 1.46 0.49 0.28 1.58 1.03 1.11 0.57 1.07 1.28 0.59 1.51 0.27 0.59 0.76 1.91 1.21 1.09 0.85 1.43 1.53 1.11 0.83 1.13 1.05 1.04 1.44 1.72 1.13 1.42 1.32 1.21 1.68 1.22 0.68 0.97 1.13 0.86 1.76 0.86 0.38 1.43 0.45 1.53 1.47 0.46 1.27 1.32 0.99 0.48 1.20 0.88 0.52 0.30 0.72 1.07 1.05 0.93 1.66 1.09 1.42 0.92 1.23 0.65 0.77 0.88 0.58 1.30 1.50 1.38 0.75 0.33 0.96 1.32 0.73 1.76 0.95 0.85 0.91 1.39 0.63 1.65 1.03 1.32 1.54 0.74 1.14 1.11 0.34 0.72 0.83 1.23 1.15 0.94 1.58 0.72 0.60 1.42 0.32 1.16 0.44 1.16 0.99 0.68 0.69 1.41 0.87 1.28 0.71 1.07 0.56 0.49 1.15 0.78 0.65 1.34 0.84 0.66 0.77 1.15 0.73 1.97 1.18 1.62 1.47 0.18 1.46 1.18 1.58 0.10 0.91 1.31 0.95 0.58 0.31 1.18 1.30 0.63 0.41 0.39 0.92 0.91 1.23 1.00 1.06 1.04 0.56 0.72 1.32 1.22 1.03 1.66 0.55 0.82 0.53 1.84 0.76 0.83 0.83 0.82 0.95 0.85 1.21 1.00 0.85 1.16 0.63 1.22 1.11 1.14 1.24 1.08 0.71 1.01 0.75 0.42 0.69 1.20 1.82 0.44 1.42 1.56 0.42 1.22 1.81 1.15 0.33 1.06 1.15 0.58 0.88 0.61 1.27 0.47 1.01 0.75 0.49 0.48 1.09 0.42 1.06 0.96 0.81 1.44 1.07 0.88 1.01 1.51 1.31 0.37 0.87 0.76 1.44 1.26 0.94 1.43 1.26 1.40 0.39 1.05 0.83 0.41 1.43 0.13 0.90 1.07 1.62 1.13 1.08 0.60 1.08 1.02 0.41 0.42 1.24 1.26 1.40 0.93 1.60 0.58 0.56 0.26 0.49 0.25 0.79 0.59 0.87 1.20 1.02 1.08 1.09 1.34 1.03 1.32 0.33 1.12 1.57 1.07 0.77 1.63 1.17 1.42 0.82 1.31 1.24 1.10 0.74 1.82 1.70 0.38 1.04 0.91 0.88 0.67 0.29 0.20 0.51 1.48 1.25 1.17 1.19 0.82 0.71 0.69 0.79 0.43 1.58 1.44 1.31 1.10 1.41 1.06 0.92 0.25 0.35 0.65 0.70 1.48 1.13 1.82 1.25 1.75 0.59 1.29 0.31 0.52 0.70 0.64 1.13 0.78 1.32 0.03 0.93 1.41 0.68 0.97 1.48 1.76 0.91 0.99 1.45 0.95 1.08 0.75 1.48 1.70 0.99 0.79 1.22 0.97 1.43 0.83 0.67 1.00 1.64 0.81 1.49 1.22 0.33 0.79 1.52 1.59 1.20 1.44 1.60 1.33 1.35 0.96 0.74 0.60 0.94 1.46 1.14 1.00 1.67 1.27 1.27 0.71 0.25 1.91 1.55 0.88 1.39 0.91 0.80 1.50 0.91 1.18 0.65 1.51 0.98 0.52 0.64 0.73 1.37 0.74 0.87 1.83 0.47 1.37 1.24 1.02 0.84 1.19 1.37 0.81 1.49 1.60 0.57 1.01 0.96 0.86 1.38 1.09 1.43 1.12 1.34 0.82 1.33 0.66 0.72 1.05 0.80 1.32 0.96 1.32 1.08 0.76 0.87 1.32 1.32 0.98 0.59 0.83 1.81 0.62 0.96 0.72 0.30 1.14 0.37 0.20 0.63 0.92 0.82 0.81 0.69 0.78 1.60 1.17 1.10 0.94 1.45 1.82 1.69 1.02 0.40 1.52 1.18 1.54 0.69 1.12 0.15 1.64 1.52 1.17 1.60 0.68 0.76 0.81 1.45 0.52 1.03 0.89 0.47 1.22 1.79 0.52 1.25 1.69 0.96 1.40 0.98 0.63 0.58 0.20 1.26 0.87 0.74 1.51 1.19 1.37 1.07 0.92 1.04 1.09 0.48 0.58 0.57 1.19 1.65 1.17 1.10 1.20 1.81 1.07 1.44 0.97 0.32 0.83 0.51 1.37 0.42 1.45 1.17 1.14 1.03 1.72 0.36 0.97 0.64 1.17 0.47 0.58 1.04 1.15 1.33 0.53 0.48 1.74 1.62 0.46 1.19 0.79 0.12 0.71 0.80 0.84 1.03 1.06 0.83 0.62 0.73 1.90 1.13 0.86 1.51 1.41 1.52 1.23 0.94 1.39 0.83 1.02 0.64 0.95 1.28 1.63 0.72 1.22 1.17 0.60 1.41 0.37 1.19 0.56 1.55 0.88 1.18 1.26 0.98 0.29 0.77 0.28 0.45 1.34 1.58 0.29 0.94 0.91 1.26 1.25 1.43 0.21 1.04 0.42 0.69 1.27 1.63 0.95 1.05 0.70 0.22 1.62 0.65 0.28 1.01 0.73 0.68 1.03 0.41 0.72 1.17 0.56 0.54 0.88 0.80 1.23 1.56 0.19 0.39 1.12 1.01 0.83 0.80 0.39 0.33 1.31 0.11 1.31 0.39 1.25 1.76 1.22 1.34 1.54 1.88 1.13 0.52 1.57 0.85 1.53 1.08 0.69 0.72 1.82 1.19 0.30 1.55 1.28 0.93 0.61 0.48 1.70 0.72 1.31 1.23 0.75 0.68 1.48 1.44 1.52 1.36 0.57 1.35 1.79 0.67 1.08 1.16 1.13 1.05 1.43 1.28 1.58 0.62 1.37 0.34 1.68 1.70 0.61 1.10 0.32 0.81 0.89 1.19 0.85 0.47 0.52 1.47 0.71 1.15 1.13 0.95 1.20 1.05 1.70 1.24 0.90 0.43 1.03 0.82 0.86 1.16 1.04 1.48 1.70 0.81 1.12 0.65 0.41 1.14 0.84 1.14 0.43 1.53 1.19 1.32 0.64 0.43 1.11 0.43 1.54 0.65 1.00 0.99 0.99 0.52 0.51 1.57 0.23 1.39 1.45 0.49 1.21 0.79 0.83 1.13 1.46 0.04 1.09 0.87 1.16 0.93 1.06 0.61 1.60 0.72 0.73 1.15 1.12 1.25 1.15 1.34 1.18 1.06 0.39 1.36 1.33 1.21 1.78 0.68 0.82 0.42 0.60 0.48 1.51 1.68 1.13 1.26 1.38 1.59 1.26 1.31 1.24 0.99 0.35 1.40 1.07 0.72 1.39 1.39 0.94 0.56 1.09 1.39 1.15 1.24 0.94 1.02 1.09 1.20 1.68 1.60 1.42 1.41 0.54 0.71 0.88 0.56 1.09 1.44 0.93 0.67 1.23 1.04 0.69 1.75 0.85 1.12 0.69 1.08 0.35 0.71 0.06 1.20 0.22 1.41 1.32 1.01 0.77 1.88 1.30 1.83 1.00 0.41 0.49 0.92 1.28 1.07 1.90 0.50 1.91 1.27 0.99 0.79 0.34 1.21 1.30 0.79 0.99 0.99 1.68 0.32 1.55 1.31 1.66 1.58 1.72 0.81 1.14 0.47 1.26 1.11 0.72 0.87 1.10 0.19 0.78 0.75 1.88 0.79 1.87 1.12 1.21 1.30 1.52 1.82 1.44 0.34 0.84 0.86 1.08 0.73 1.54 1.20 1.53 0.98 1.35 0.97 1.03 0.91 1.03 1.32 1.67 1.64 0.88 0.44 1.54 0.82 1.63 0.52 1.00 0.55 1.61 0.93 0.79 1.18 0.56 0.28 1.18 1.73 0.42 0.02 1.33 1.05 0.86 0.12 1.08 1.22 1.17 1.32 0.98 1.76 1.00 1.79 0.97 1.24 1.68 1.34 1.10 0.97 0.96 0.83 1.74 0.73 1.19 0.86 0.54 0.72 0.68 0.73 1.02 1.03 1.22 1.72 0.75 1.30 1.78 0.76 1.17 0.43 0.54 1.54 0.91 1.63 1.77 1.23 1.32 1.50 1.61 0.88 1.91 1.07 1.30 1.19 1.33 1.85 0.90 0.95 0.64 0.40 0.93 1.19 0.89 1.81 0.90 0.85 0.86 0.49 0.77 1.63 1.30 0.96 0.85 1.02 0.49 0.89 1.05 1.68 0.77 1.43 0.17 0.47 1.22 1.19 0.65 1.09 1.30 0.17 0.96 0.65 0.61 0.88 1.64 1.60 1.04 1.07 1.32 1.23 0.51 0.53 1.24 0.13 0.67 0.70 0.48 1.07 1.91 0.76 1.51 0.94 0.40 1.76 1.55 1.26 0.41 1.23 1.40 1.20 1.65 1.70 1.25 1.22 1.73 0.69 1.33 1.78 1.63 1.45 0.53 1.25 0.49 0.58 0.83 0.96 0.68 0.61 1.43 1.09 1.80 1.38 1.40 0.86 0.69 0.21 1.02 1.16 1.93 1.40 0.54 1.24 1.03 1.15 0.67 1.60 1.00 0.61 1.14 1.43 0.78 1.05 1.09 1.30 0.95 0.78 1.08 1.70 0.86 0.56 1.08 1.00 1.13 1.49 1.07 1.10 0.56 1.64 1.35 0.67 0.65 1.79 1.45 0.84 0.34 0.83 1.56 0.50 0.43 0.96 0.90 1.34 1.21 1.10 1.93 0.87 1.20 1.32 1.15 0.96 1.55 0.90 0.62 0.79 0.40 1.54 0.82 0.77 0.87 1.59 0.64 1.39 1.11 1.49 0.85 0.74 1.25 0.50 1.06 0.93 1.06 1.77 1.36 0.90 1.39 1.04 0.95 0.87 1.12 1.32 0.83 0.36 0.72 0.95 0.16 1.24 1.36 1.10 0.54 0.96 0.51 0.97 1.42 1.51 1.22 0.49 0.89 0.12 0.73 1.39 0.96 0.10 0.65 1.04 1.22 1.12 0.99 1.19 0.92 0.95 1.52 1.18 1.30 1.01 1.38 0.91 1.05 0.66 1.23 0.88 0.70 1.18 1.07 1.11 1.06 1.13 1.49 0.98 0.61 0.82 1.41 0.35 0.74 1.15 0.71 1.42 1.02 1.10 0.97 1.09 1.27 0.61 1.53 1.55 0.60 0.15 1.10 0.45 1.51 0.81 0.62 1.63 0.84 0.74 0.95 0.85 1.03 0.97 0.07 0.71 0.90 0.66 1.37 0.85 0.69 1.09 0.90 0.95 0.46 0.56 0.50 0.62 0.88 1.11 1.13 0.60 1.69 1.05 1.36 1.94 0.55 1.35 0.76 1.19 0.97 0.62 1.17 1.00 1.84 0.99 0.93 1.01 0.84 1.69 0.94 1.25 0.66 0.94 0.88 1.64 0.89 1.33 0.50 1.10 0.44 1.32 1.67 0.99 0.37 0.72 1.30 0.79 1.55 1.38 0.87 0.30 1.28 0.81 1.96 1.12 0.98 0.76 0.76 1.17 1.42 1.44 0.85 0.69 0.99 0.83 1.08 0.61 0.76 1.13 1.32 1.10 0.70 0.97 0.60 1.59 1.04 0.75 1.28 1.28 1.50 1.12 1.24 0.94 1.16 0.72 1.32 0.79 0.68 1.47 0.90 1.30 1.12 0.82 1.48 0.67 1.21 0.56 0.53 0.46 0.57 1.15 1.01 0.91 0.69 0.97 1.45 1.52 1.32 0.96 1.44 0.78 1.42 1.11 0.84 0.62 1.76 1.30 0.70 1.45 1.59 0.97 0.70 0.61 0.84 0.83 0.21 0.93 0.94 0.57 0.61 1.18 0.95 1.15 0.69 1.04 1.03 1.33 1.51 0.75 1.52 1.63 1.18 0.36 0.60 0.90 1.12 1.59 0.57 0.72 1.34 0.55 0.77 1.11 0.83 0.64 0.44 1.08 0.84 0.73 1.37 0.65 1.71 0.55 0.99 0.54 1.03 0.72 0.99 1.10 1.68 0.17 1.02 0.74 0.68 0.29 1.11 1.53 0.19 1.10 1.36 0.51 0.75 1.21 1.05 0.55 1.06 0.86 0.96 0.94 1.08 1.69 1.16 1.01 1.30 1.53 1.76 1.04 1.27 1.24 1.56 1.05 0.51 1.71 1.53 1.12 0.87 0.80 1.03 0.39 0.92 0.97 0.96 1.18 1.26 0.56 1.22 1.45 0.53 1.21 0.81 0.68 0.14 0.71 1.29 1.49 1.02 0.90 1.48 1.21 1.50 0.57 1.38 0.47 1.18 0.98 0.01 0.65 1.14 1.32 1.45 1.65 1.27 1.45 0.62 0.50 1.42 0.86 1.09 1.72 1.01 1.25 1.36 1.17 1.26 0.94 1.29 1.19 1.12 1.31 0.28 0.87 0.88 0.50 1.06 0.25 0.93 1.09 1.41 0.80 0.75 0.39 0.31 0.61 0.20 1.17 0.74 1.17 1.76 1.61 0.90 1.89 1.35 1.12 0.25 1.44 0.64 1.03 1.41 1.37 1.57 1.10 0.56 0.95 0.95 1.15 1.40 0.67 1.02 0.52 1.71 0.26 0.79 1.30 0.95 0.83 1.20 0.85 1.20 1.11 0.34 0.99 1.29 0.49 0.47 1.57 0.97 0.52 1.13 0.98 0.49 0.59 0.74 0.46 1.23 0.08 0.82 1.32 0.74 1.42 0.82 1.37 0.83 0.55 0.72 1.04 1.34 0.89 1.08 1.01 0.91 0.89 1.16 0.83 1.00 1.11 1.26 1.60 0.39 1.07 0.69 1.30 0.74 1.11 0.55 0.14 1.20 1.19 1.21 0.26 0.28 1.02 0.87 0.64 0.78 0.35 0.80 0.50 0.85 1.36 1.72 0.85 1.52 0.29 1.07 0.94 0.93 0.88 0.59 1.05 1.22 1.84 1.06 0.57 0.95 1.30 0.44 1.59 0.21 1.69 0.45 1.61 0.60 1.18 1.02 0.56 0.62 1.26 0.75 0.60 0.76 1.37 1.06 1.16 0.85 1.53 0.48 1.67 0.64 1.26 1.08 0.89 1.23 1.39 0.97 0.67 0.88 0.94 1.01 1.20 0.94 1.15 0.87 0.50 0.67 0.17 1.59 0.45 1.20 0.79 0.82 0.91 0.50 0.65 0.95 0.36 1.57 1.32 1.34 0.95 0.59 1.77 1.18 0.98 1.05 0.56 1.23 1.58 0.33 1.24 1.08 1.17 0.12 1.07 1.30 0.48 1.14 1.07 0.46 1.70 0.83 0.39 1.75 1.80 1.22 0.34 0.63 0.93 0.99 1.23 1.02 1.20 0.95 1.49 1.31 0.93 1.46 1.21 1.30 1.28 1.03 0.80 0.14 1.42 0.74 0.44 1.36 0.92 0.89 1.72 0.60 0.35 0.97 1.26 1.55 0.79 1.17 1.23 1.32 0.46 1.32 0.82 0.52 0.98 1.16 0.62 1.35 0.81 1.51 0.59 1.61 0.63 0.96 1.10 1.53 1.35 0.45 1.51 0.92 0.39 1.21 0.85 0.96 1.89 0.73 0.52 0.85 1.14 1.01 1.10 0.80 1.37 0.63 1.22 1.39 0.64 0.60 1.16 1.14 1.01 0.51 0.21 0.68 1.17 0.59 0.22 0.72 0.62 1.49 0.90 0.43 0.48 1.01 0.59 0.69 1.02 0.14 0.56 0.58 1.50 1.00 0.55 0.32 0.07 1.02 1.70 0.50 0.48 0.82 0.66 0.67 0.71 0.91 1.63 1.00 1.67 0.85 0.74 1.40 0.98 0.79 0.86 0.85 0.81 1.40 1.17 1.14 0.89 1.16 1.54 0.65 1.18 0.43 0.68 1.74 1.24 1.35 0.81 0.44 0.86 1.08 0.93 0.93 1.27 0.34 1.25 1.01 1.49 1.36 1.28 0.83 0.61 1.62 1.38 1.03 0.90 1.28 0.33 0.63 0.30 1.41 0.95 0.99 0.88 0.61 1.43 1.67 0.62 1.45 1.35 1.24 0.59 1.07 0.73 0.51 1.66 0.58 0.35 1.06 0.90 0.36 1.13 0.36 1.32 1.75 1.28 0.92 1.51 0.79 0.69 0.26 0.22 0.98 0.40 1.78 0.71 1.63 0.18 1.59 1.79 1.17 1.34 0.95 1.08 1.08 1.05 1.13 1.17 0.84 1.13 1.86 1.76 0.68 1.48 1.43 0.61 1.35 0.69 0.80 1.04 0.54 0.22 1.36 0.78 1.95 1.82 1.76 1.31 1.52 0.71 1.07 1.54 1.27 0.72 1.00 0.96 0.85 1.21 0.57 1.41 0.91 1.34 0.82 1.10 1.45 0.28 1.13 0.94 1.06 0.49 1.41 1.61 0.63 1.48 0.82 0.72 1.13 0.39 1.72 1.30 1.30 1.71 1.41 0.85 1.29 0.53 0.80 0.97 0.95 1.62 0.35 0.49 0.42 1.45 0.38 1.32 1.33 1.13 0.66 1.20 0.34 1.67 0.86 1.56 1.10 0.58 0.53 0.93 0.96 1.08 1.13 1.05 0.42 1.19 1.17 1.04 1.11 0.65 0.35 0.78 1.38 0.91 1.44 0.84 1.23 0.76 0.31 0.81 0.99 0.83 1.38 0.68 0.58 1.45 0.52 0.39 1.58 0.81 1.14 0.43 1.57 0.71 1.00 0.62 1.53 1.16 1.32 1.40 1.16 0.84 1.08 0.59 0.52 0.69 1.05 1.02 1.30 0.49 1.26 1.30 0.58 0.71 1.30 0.80 0.96 1.15 0.85 0.70 1.14 1.03 0.51 1.80 1.79 1.12 0.42 0.85 0.88 0.89 0.66 0.63 1.31 1.67 0.53 0.55 0.76 0.87 0.63 1.08 1.96 0.47 0.63 1.35 1.87 0.67 0.92 1.16 1.09 0.39 1.20 1.31 1.53 1.24 0.83 0.57 0.52 1.16 1.36 1.64 0.75 0.77 1.62 0.91 0.76 1.34 1.25 0.93 0.83 0.93 1.49 1.46 0.53 1.15 1.12 1.14 1.10 0.57 0.85 1.43 0.78 0.58 1.43 0.81 0.67 0.91 1.23 1.17 0.97 0.66 1.11 0.99 1.70 0.91 1.03 1.15 1.11 1.84 1.23 0.78 0.38 1.05 0.05 0.36 1.53 1.14 1.81 0.84 1.69 1.04 1.10 1.52 0.91 1.75 1.00 1.04 0.23 0.97 0.30 0.32 1.34 1.47 0.59 0.66 1.07 0.99 0.90 0.39 0.88 0.96 1.67 1.25 1.08 0.19 0.55 0.22 0.97 1.06 1.01 0.84 0.42 1.26 1.35 1.14 1.78 1.09 1.09 1.36 1.57 1.56 1.05 1.03 1.48 0.59 0.78 0.57 1.26 0.52 0.47 0.82 1.75 0.71 1.28 1.02 1.61 0.97 1.37 0.67 1.07 1.33 0.70 1.05 0.72 0.57 1.21 1.43 1.32 0.80 1.21 1.43 1.39 1.47 0.39 0.59 1.41 1.30 0.82 1.07 0.92 1.72 1.03 1.10 1.30 0.94 1.71 1.31 0.77 0.86 0.93 0.62 1.38 0.45 0.28 0.74 1.16 0.33 0.62 1.53 0.34 0.42 1.86 1.15 0.52 1.81 1.47 0.79 1.36 1.05 1.76 0.83 0.26 0.10 1.59 1.78 1.12 0.98 0.93 0.62 0.14 0.88 0.86 1.45 0.91 0.86 0.29 0.58 0.86 0.41 0.33 0.39 0.38 0.44 0.50 0.73 1.49 1.24 1.28 0.58 1.19 0.85 1.15 1.03 1.13 0.47 0.61 0.91 1.23 1.30 0.42 1.36 0.65 0.27 1.30 1.12 1.30 0.97 1.41 1.45 1.41 1.00 0.78 1.04 1.27 0.74 0.38 0.59 0.71 0.95 0.72 0.49 1.03 1.47 1.44 0.98 0.84 0.90 0.90 0.61 1.27 0.85 1.45 0.66 0.31 1.16 0.67 1.05 1.10 1.15 1.43 1.40 1.12 0.88 1.22 1.19 0.85 1.13 1.49 1.45 0.40 0.85 1.26 0.78 1.41 0.90 1.06 1.12 1.59 0.21 1.50 1.30 1.45 0.65 1.21 0.75 0.72 0.67 1.49 1.33 0.37 0.75 1.52 0.61 0.87 0.92 0.21 0.72 0.65 1.60 1.46 1.46 0.94 1.16 0.57 1.32 0.71 1.37 0.94 1.34 0.80 1.19 1.49 0.68 1.27 0.99 0.63 0.92 1.59 1.00 0.56 1.11 0.41 0.52 0.47 1.17 1.13 1.27 1.25 1.73 1.23 0.26 1.18 1.44 0.25 0.93 0.78 1.08 1.52 1.53 0.45 1.24 1.06 1.18 0.48 0.83 0.63 0.58 1.26 0.56 0.46 0.31 1.53 1.43 0.99 1.03 1.66 1.01 0.80 1.03 1.10 0.99 0.94 1.53 1.56 0.71 0.59 1.25 1.42 1.16 0.64 0.84 0.46 1.02 1.05 1.53 0.91 0.87 0.07 1.06 1.51 0.66 0.80 1.21 1.60 0.62 0.55 0.55 1.32 1.27 1.63 0.51 0.33 0.39 0.80 1.04 0.22 1.39 0.63 0.22 0.96 0.48 0.31 1.51 1.59 0.99 0.57 0.76 0.90 1.29 0.61 1.00 1.04 1.83 0.99 0.89 1.89 0.45 0.40 0.81 1.73 1.23 0.31 1.19 1.14 0.90 1.81 0.55 1.29 0.52 0.44 0.22 0.79 0.53 1.64 1.18 1.16 1.66 1.39 0.68 0.33 1.27 0.48 1.01 1.22 1.04 0.94 1.00 0.95 0.92 0.89 0.94 1.52 1.52 0.45 0.45 0.78 0.94 1.55 1.03 1.48 0.44 1.33 1.15 1.00 0.85 1.18 0.94 0.38 0.61 0.67 1.62 0.78 0.71 0.51 1.11 0.80 1.40 1.00 0.42 1.62 0.88 1.06 0.48 0.29 1.28 1.15 0.42 1.46 1.26 0.87 0.96 0.91 1.81 1.91 0.90 1.49 0.32 0.60 1.00 0.90 0.86 0.18 0.98 1.41 1.61 0.61 0.95 0.93 1.42 0.99 1.35 1.10 1.04 1.47 0.60 0.31 0.43 0.75 0.14 0.66 0.45 1.33 0.79 1.17 1.09 1.55 0.63 1.11 0.35 0.71 0.96 1.42 1.52 0.81 0.33 0.42 0.75 1.18 1.01 0.76 1.49 0.54 0.95 0.79 0.25 1.26 0.52 0.60 0.84 0.70 0.88 0.95 1.87 1.16 1.47 0.99 1.23 1.08 1.20 0.48 1.36 1.65 0.42 0.91 0.67 0.45 0.73 1.18 0.53 0.49 1.27 0.94 1.02 0.68 1.88 0.67 0.91 1.13 0.58 1.60 0.65 1.82 1.45 0.99 0.35 0.95 0.97 1.13 0.90 1.20 0.98 1.04 1.20 1.22 1.20 0.05 0.86 1.24 1.87 1.26 0.70 0.84 1.09 0.65 1.78 1.78 1.74 1.63 0.99 0.72 0.65 1.05 0.65 0.81 0.51 0.73 1.29 0.89 0.54 0.37 0.40 1.07 0.98 1.07 1.54 1.16 1.57 0.71 0.49 0.72 0.59 1.22 1.03 0.25 0.64 0.89 0.78 1.18 0.65 1.73 1.04 0.37 1.09 0.82 0.60 0.59 0.99 1.08 0.92 1.60 0.95 0.61 1.44 1.49 1.05 1.27 1.10 1.69 0.73 0.77 1.05 0.54 1.17 0.08 0.94 1.64 0.17 0.64 1.05 0.71 1.34 1.18 0.62 1.63 1.38 0.69 0.76 1.51 0.84 1.02 1.26 0.68 0.93 1.06 0.43 1.07 0.75 1.21 1.12 0.72 1.23 0.95 0.63 0.94 1.04 1.24 1.62 0.75 1.21 0.53 1.59 1.40 0.84 0.69 1.45 1.46 0.81 0.69 0.88 0.90 1.57 1.23 1.04 0.76 1.80 0.88 0.88 0.71 0.90 1.68 0.81 1.03 0.56 1.06 1.34 1.35 1.09 1.12 1.56 1.37 1.16 1.73 0.53 0.77 1.83 0.77 0.59 1.25 0.52 0.59 1.27 0.78 1.53 0.49 0.77 1.43 1.12 0.97 0.59 1.08 1.19 1.05 1.65 0.94 1.62 1.03 1.49 1.25 0.69 1.09 0.61 1.39 0.69 1.37 1.10 0.70 1.29 1.07 1.06 1.11 1.54 0.57 0.94 1.04 0.56 1.09 1.66 0.89 0.84 0.63 1.71 1.22 1.09 0.95 1.30 0.83 1.20 0.88 1.21 0.77 1.05 0.96 0.34 1.06 1.11 1.11 1.03 0.83 1.63 1.26 0.83 1.78 0.48 1.17 1.56 0.48 0.80 1.32 1.29 1.31 1.08 1.23 0.76 1.22 0.81 0.32 0.58 0.68 0.76 0.74 0.79 0.94 0.67 1.73 0.65 1.36 1.47 1.84 0.63 1.63 1.56 1.10 0.06 1.18 0.63 1.15 1.16 1.04 1.36 0.78 0.81 0.76 0.73 0.52 1.67 0.81 1.11 1.36 0.68 0.99 1.47 0.76 0.24 1.44 1.55 0.62 0.36 0.65 0.97 1.44 0.33 0.87 1.15 1.61 1.77 1.17 1.75 1.86 0.71 1.60 0.51 0.63 0.59 1.95 1.46 1.21 0.64 1.22 0.31 0.64 0.43 1.31 0.73 1.17 0.46 0.70 0.98 1.85 1.63 1.13 1.19 1.88 1.44 0.62 0.93 0.84 1.07 1.55 1.32 1.24 1.50 0.76 0.28 1.04 0.40 1.00 1.54 1.42 0.98 0.73 1.32 1.28 0.73 1.18 0.56 1.83 0.35 0.52 1.19 1.54 1.75 1.19 1.41 1.26 0.66 1.30 0.55 0.36 0.41 0.33 0.96 1.01 0.75 0.95 1.10 0.54 1.02 1.12 1.35 1.83 0.35 0.97 1.72 1.18 0.87 1.10 1.66 0.15 0.64 1.37 0.57 0.58 0.65 1.04 1.09 0.99 1.01 1.34 0.29 0.88 1.03 0.99 1.10 1.11 0.22 0.48 1.40 0.38 1.77 1.05 1.28 0.30 1.00 1.02 0.18 1.45 0.87 0.91 0.57 0.70 1.50 0.58 1.25 0.94 1.37 0.88 1.03 1.93 0.83 0.32 1.85 1.22 1.22 0.69 1.14 1.57 1.57 0.51 1.10 1.85 1.45 1.11 0.90 0.49 1.00 0.75 0.59 1.58 0.08 0.58 1.66 0.83 1.29 1.06 0.81 0.85 0.63 1.72 1.02 1.28 1.01 0.87 0.99 1.40 0.72 1.28 1.13 1.62 1.46 1.81 0.60 0.51 0.64 1.78 1.43 0.67 0.08 1.06 1.00 1.14 1.43 1.11 0.53 0.99 0.42 1.27 0.47 1.25 1.00 0.77 1.08 0.88 1.00 1.23 1.39 0.72 0.78 1.38 1.57 1.30 0.16 1.01 0.34 0.75 1.29 1.78 0.96 0.53 1.60 0.95 1.11 0.80 0.51 0.20 0.55 1.08 1.06 1.36 1.37 0.74 0.62 1.02 1.18 0.54 1.30 0.77 1.18 1.30 0.77 0.77 0.98 1.05 0.96 1.44 0.50 0.97 0.68 0.72 1.54 0.65 0.75 1.26 1.00 0.61 1.04 0.09 0.25 1.06 0.53 1.52 0.66 1.17 1.49 1.21 1.15 0.87 1.28 0.83 1.67 1.03 0.84 0.74 1.26 1.30 1.28 0.83 1.32 0.28 0.89 0.84 1.35 0.94 0.82 0.89 0.20 1.21 1.05 1.13 1.74 1.10 1.25 0.95 0.93 1.37 0.71 1.85 0.90 1.68 0.55 0.22 1.50 0.80 0.37 0.85 0.35 1.12 0.88 1.15 0.30 0.62 0.71 1.08 1.28 1.33 1.32 0.58 0.98 1.37 1.30 1.45 1.17 1.24 0.64 0.85 0.91 0.96 0.97 0.23 0.80 1.07 0.11 0.95 1.02 1.43 1.54 0.96 1.45 0.75 0.60 1.04 1.10 1.12 1.05 1.31 0.91 0.98 1.03 1.10 1.24 1.36 0.41 0.48 1.54 0.96 0.84 0.64 1.00 1.00 1.12 1.89 0.69 1.05 1.80 0.76 0.68 1.81 0.46 0.96 0.53 1.14 0.91 1.31 0.56 1.95 1.63 1.71 0.70 1.04 0.92 1.54 0.92 0.69 0.65 0.39 1.56 1.56 1.31 0.37 1.19 1.55 1.15 1.15 1.02 0.34 0.98 1.54 0.23 0.30 0.88 1.06 1.21 0.91 1.50 1.38 1.58 0.52 1.19 1.57 0.85 1.15 0.78 0.75 0.93 0.89 0.72 1.24 0.58 0.45 1.42 0.77 0.77 1.74 0.95 1.17 0.21 0.63 1.02 0.99 1.42 0.74 0.85 1.09 1.15 1.50 1.36 0.58 0.56 1.08 0.62 1.31 0.59 1.81 1.31 0.55 0.70 0.89 1.29 0.96 1.50 1.00 0.75 0.99 0.90 1.82 1.33 1.34 1.07 1.52 0.96 1.13 1.37 0.19 1.00 1.09 0.62 1.37 0.67 0.67 0.44 1.09 1.62 1.69 1.59 1.09 1.29 1.19 1.25 1.30 0.52 0.75 1.49 0.49 1.49 0.74 1.65 1.71 1.26 0.98 0.61 1.38 1.28 1.54 0.94 0.78 1.23 1.58 1.66 0.88 1.23 1.08 1.44 1.16 1.18 0.54 1.21 0.68 0.48 1.03 1.05 0.87 1.33 1.00 1.52 0.15 1.50 0.65 1.01 0.64 0.96 0.99 1.09 1.65 1.88 0.99 1.48 0.21 1.31 0.80 1.10 0.60 1.18 0.53 1.07 0.38 1.35 1.18 1.03 1.03 1.52 0.84 0.87 0.81 0.27 1.03 1.57 0.96 0.89 0.93 0.66 0.97 1.68 0.47 1.00 0.62 0.50 1.51 1.51 1.56 0.95 1.15 1.22 1.26 1.59 1.04 0.51 1.27 1.18 0.91 1.22 1.71 0.98 1.11 1.55 1.27 1.25 1.01 1.53 0.56 1.48 0.39 1.62 1.17 0.40 0.99 1.60 1.36 1.93 1.08 1.12 0.99 0.78 0.85 0.29 0.45 1.01 0.75 0.50 1.44 1.01 1.52 1.13 1.19 1.34 0.55 0.61 0.85 1.56 1.72 1.10 0.62 0.99 1.73 1.31 1.40 0.59 0.92 0.80 1.79 0.36 0.60 0.90 0.37 1.14 0.31 0.24 1.33 1.31 0.74 1.23 0.93 1.07 1.56 0.94 1.00 1.71 1.28 1.04 1.08 1.72 1.41 0.34 1.20 1.80 0.27 1.09 1.86 1.03 1.01 0.76 1.28 0.61 1.08 1.20 0.83 1.55 0.89 0.96 0.54 1.04 0.79 1.00 1.26 1.05 1.01 0.28 0.28 0.84 0.55 1.53 0.96 1.61 1.97 0.93 0.34 1.31 1.09 1.77 1.36 1.62 0.64 1.65 0.81 1.30 1.52 0.74 1.90 1.32 1.93 0.38 0.21 1.40 1.01 1.65 1.00 0.73 1.19 1.57 0.86 0.34 0.67 0.85 0.42 0.44 0.42 0.61 0.50 1.93 1.19 1.89 0.85 1.83 0.99 1.02 1.26 1.23 0.44 1.52 0.24 1.21 0.76 1.29 0.84 1.78 0.80 1.22 1.28 0.69 1.46 1.11 1.08 1.66 1.40 1.39 1.12 0.31 1.43 1.14 0.84 0.31 0.59 1.30 0.59 1.13 0.71 1.76 1.56 1.32 0.60 0.62 1.31 0.59 0.55 1.03 1.66 1.02 0.87 1.13 1.30 1.50 0.49 1.79 0.68 1.02 0.82 0.98 1.59 0.88 0.33 1.51 0.24 1.25 0.84 1.57 0.62 1.14 1.33 1.16 1.03 1.28 1.83 0.97 0.86 1.54 0.74 1.17 0.59 1.10 0.79 1.56 0.73 0.52 1.63 1.07 0.85 0.50 0.62 0.08 1.31 1.65 0.69 1.03 1.23 0.70 0.80 0.43 0.96 0.60 0.62 1.26 1.01 1.14 1.22 1.09 0.86 0.58 0.54 0.83 0.75 1.79 0.79 1.07 1.17 0.35 1.33 1.26 0.36 0.97 1.64 1.12 0.80 1.04 1.31 1.11 0.39 1.60 1.13 0.93 0.35 1.09 0.89 1.03 0.76 0.84 1.07 0.88 0.65 1.20 0.78 1.02 1.21 0.35 0.29 0.64 0.56 1.33 1.10 1.70 1.36 0.25 0.49 1.28 1.05 1.11 1.78 1.00 0.75 1.33 0.63 1.69 0.71 1.65 1.38 1.67 1.88 1.16 1.05 1.53 0.92 0.93 0.77 1.70 1.28 0.57 1.01 1.11 1.28 0.53 1.11 0.40 1.11 0.37 1.00 1.25 1.54 0.63 1.10 0.84 1.37 1.29 1.66 1.10 1.15 1.60 0.82 1.24 0.55 1.08 1.51 1.49 0.49 0.35 0.47 0.97 1.59 1.22 0.66 1.20 0.95 1.06 0.79 1.70 0.91 0.90 1.11 0.47 0.51 1.18 1.02 0.81 0.42 1.86 0.36 1.89 0.85 1.09 1.25 0.96 1.59 1.58 0.24 1.29 0.87 1.73 0.64 0.50 1.57 1.13 0.42 1.23 0.97 0.90 1.12 0.39 0.73 1.40 1.00 0.71 1.16 0.76 0.97 0.84 0.60 1.45 1.00 0.30 1.00 1.19 1.06 0.82 0.55 0.75 0.90 0.42 0.90 0.86 0.42 1.40 0.67 1.05 0.53 1.65 1.54 0.65 1.42 0.40 0.68 0.51 0.62 0.65 1.11 1.40 1.21 0.56 1.65 1.57 0.96 0.72 1.04 1.11 0.84 1.43 1.67 1.12 0.87 0.81 1.28 0.52 1.01 0.37 0.70 1.85 1.14 0.17 0.93 0.64 0.80 1.29 1.01 0.75 1.18 1.86 0.76 0.94 1.45 1.42 1.24 0.81 0.83 0.57 1.27 0.52 1.28 0.53 1.22 1.16 0.82 0.84 1.38 1.35 1.08 0.99 1.03 0.70 0.79 1.62 0.48 1.13 0.96 1.05 0.93 1.58 1.21 0.33 1.18 1.44 1.45 0.59 1.23 1.35 0.55 1.08 1.11 0.79 1.86 1.27 1.04 0.53 1.26 0.85 0.55 1.72 0.70 1.48 0.59 0.95 0.80 1.17 1.23 0.99 0.80 1.86 1.10 1.09 1.26 0.81 0.21 0.82 0.83 0.86 1.12 0.55 0.84 0.83 1.68 1.15 1.06 0.33 0.41 0.52 0.35 0.49 0.84 1.49 1.60 1.07 1.15 1.64 0.34 1.06 0.27 0.52 1.24 1.50 1.26 1.33 1.34 1.17 1.12 0.85 1.00 1.44 0.54 1.15 0.54 0.91 0.41 0.16 1.27 0.30 0.69 1.13 0.44 1.22 0.96 1.29 0.99 1.12 0.81 1.42 1.47 1.17 0.77 1.53 0.99 0.57 0.45 0.72 1.01 1.46 1.01 0.94 1.49 0.54 0.33 1.65 1.30 0.69 1.15 1.12 1.04 0.82 0.38 1.39 0.48 1.35 1.60 1.49 0.34 1.38 1.00 0.47 0.84 1.38 0.37 0.13 1.19 0.92 1.50 0.95 1.16 1.46 0.59 0.84 0.98 1.61 0.24 0.28 1.23 1.07 1.16 1.03 0.17 1.91 1.26 0.65 0.16 0.18 1.07 0.68 1.24 1.03 1.36 0.56 0.97 0.21 1.84 0.46 1.18 0.69 1.22 1.85 1.46 0.13 1.05 0.57 1.09 0.75 0.91 1.05 0.95 0.99 0.49 0.82 0.82 1.11 1.85 0.43 1.00 0.83 1.36 1.33 1.00 1.90 1.40 0.77 0.20 1.14 0.22 1.36 1.47 1.08 1.43 1.63 1.07 0.48 0.86 1.88 1.89 1.77 0.73 0.64 1.31 1.62 1.75 0.56 1.44 1.55 1.15 1.31 0.65 0.66 0.60 0.37 0.33 0.78 0.67 1.00 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lov7-PV7wW9o",
        "outputId": "26a21d36-8594-45a7-d819-ea8a1af595d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%cuda --name GPU_features.cu\r\n",
        "#include<cuda.h>\r\n",
        "#include<stdio.h>\r\n",
        "void printDevProp(cudaDeviceProp);\r\n",
        "int main()\r\n",
        "{\r\n",
        "    int devCount;\r\n",
        "    cudaGetDeviceCount(&devCount);\r\n",
        "    for(int i=0;i<devCount;++i)\r\n",
        "    {\r\n",
        "        cudaDeviceProp devp;\r\n",
        "        cudaGetDeviceProperties(&devp,i);\r\n",
        "        printDevProp(devp);\r\n",
        "    }\r\n",
        "    return 0;\r\n",
        "}\r\n",
        "void printDevProp(cudaDeviceProp devProp)\r\n",
        "{\r\n",
        "    printf(\" Major revision number : %d\\n\",devProp.major);\r\n",
        "    printf(\" Minor revision number : %d\\n\",devProp.minor);\r\n",
        "    printf(\" Name : %s\\n\",devProp.name);\r\n",
        "    printf(\" Total global memory : %lu\\n\",devProp.totalGlobalMem);\r\n",
        "    printf(\" Total shared memory per block : %lu\\n\",devProp.sharedMemPerBlock);\r\n",
        "    printf(\" Total registers per block : %d\\n\", devProp.regsPerBlock);\r\n",
        "    printf(\" Warp size : %d\\n\",devProp.warpSize);\r\n",
        "    printf(\" Maximum memory pitch : %lu\\n\",devProp.memPitch);\r\n",
        "    printf(\" Maximum threads per block : %d\\n\",devProp.maxThreadsPerBlock);\r\n",
        "    for(int i=0;i<3;++i)\r\n",
        "        printf (\" Maximum dimension %d of block : %d\\n\",i,devProp.maxThreadsDim[i]);\r\n",
        "    for(int i=0;i<3;++i)\r\n",
        "        printf (\" Maximum dimension %d of grid : %d\\n\",i,devProp.maxGridSize[i]);\r\n",
        "    printf(\" Clock rate : %d\\n\",devProp.clockRate);\r\n",
        "    printf(\" Total constant memory : %lu\\n\",devProp.totalConstMem);\r\n",
        "    printf(\" Texture alignment : %lu\\n\",devProp.textureAlignment);\r\n",
        "    printf(\" Concurrent copy and execution : %s\\n\",(devProp.deviceOverlap?\"Yes\":\"No\"));\r\n",
        "    printf(\" Number of multiprocessors : %d\\n\",devProp.multiProcessorCount);\r\n",
        "    return;\r\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/GPU_features.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEjpCcQPyfwC"
      },
      "source": [
        "!nvcc /content/src/GPU_features.cu -o GPU_features"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM6i_Zwkyr9m",
        "outputId": "d7e11e6d-fa75-451c-ea78-d83b2ed86adb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!/content/GPU_features"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Major revision number : 7\n",
            " Minor revision number : 5\n",
            " Name : Tesla T4\n",
            " Total global memory : 15843721216\n",
            " Total shared memory per block : 49152\n",
            " Total registers per block : 65536\n",
            " Warp size : 32\n",
            " Maximum memory pitch : 2147483647\n",
            " Maximum threads per block : 1024\n",
            " Maximum dimension 0 of block : 1024\n",
            " Maximum dimension 1 of block : 1024\n",
            " Maximum dimension 2 of block : 64\n",
            " Maximum dimension 0 of grid : 2147483647\n",
            " Maximum dimension 1 of grid : 65535\n",
            " Maximum dimension 2 of grid : 65535\n",
            " Clock rate : 1590000\n",
            " Total constant memory : 65536\n",
            " Texture alignment : 512\n",
            " Concurrent copy and execution : Yes\n",
            " Number of multiprocessors : 40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gnWB6fXy-kX",
        "outputId": "7e437ef7-af50-4a4a-8285-1505dbaa2f8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi -q"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "==============NVSMI LOG==============\n",
            "\n",
            "Timestamp                                 : Tue Mar  9 21:02:16 2021\n",
            "Driver Version                            : 460.32.03\n",
            "CUDA Version                              : 11.2\n",
            "\n",
            "Attached GPUs                             : 1\n",
            "GPU 00000000:00:04.0\n",
            "    Product Name                          : Tesla T4\n",
            "    Product Brand                         : Tesla\n",
            "    Display Mode                          : Enabled\n",
            "    Display Active                        : Disabled\n",
            "    Persistence Mode                      : Disabled\n",
            "    MIG Mode\n",
            "        Current                           : N/A\n",
            "        Pending                           : N/A\n",
            "    Accounting Mode                       : Disabled\n",
            "    Accounting Mode Buffer Size           : 4000\n",
            "    Driver Model\n",
            "        Current                           : N/A\n",
            "        Pending                           : N/A\n",
            "    Serial Number                         : 1561920022586\n",
            "    GPU UUID                              : GPU-09bf90f4-c633-606e-e9b2-0a7f0dcc24e9\n",
            "    Minor Number                          : 0\n",
            "    VBIOS Version                         : 90.04.96.00.01\n",
            "    MultiGPU Board                        : No\n",
            "    Board ID                              : 0x4\n",
            "    GPU Part Number                       : 900-2G183-6300-T00\n",
            "    Inforom Version\n",
            "        Image Version                     : G183.0200.00.02\n",
            "        OEM Object                        : 1.1\n",
            "        ECC Object                        : 5.0\n",
            "        Power Management Object           : N/A\n",
            "    GPU Operation Mode\n",
            "        Current                           : N/A\n",
            "        Pending                           : N/A\n",
            "    GPU Virtualization Mode\n",
            "        Virtualization Mode               : Pass-Through\n",
            "        Host VGPU Mode                    : N/A\n",
            "    IBMNPU\n",
            "        Relaxed Ordering Mode             : N/A\n",
            "    PCI\n",
            "        Bus                               : 0x00\n",
            "        Device                            : 0x04\n",
            "        Domain                            : 0x0000\n",
            "        Device Id                         : 0x1EB810DE\n",
            "        Bus Id                            : 00000000:00:04.0\n",
            "        Sub System Id                     : 0x12A210DE\n",
            "        GPU Link Info\n",
            "            PCIe Generation\n",
            "                Max                       : 3\n",
            "                Current                   : 1\n",
            "            Link Width\n",
            "                Max                       : 16x\n",
            "                Current                   : 16x\n",
            "        Bridge Chip\n",
            "            Type                          : N/A\n",
            "            Firmware                      : N/A\n",
            "        Replays Since Reset               : 0\n",
            "        Replay Number Rollovers           : 0\n",
            "        Tx Throughput                     : 0 KB/s\n",
            "        Rx Throughput                     : 0 KB/s\n",
            "    Fan Speed                             : N/A\n",
            "    Performance State                     : P8\n",
            "    Clocks Throttle Reasons\n",
            "        Idle                              : Active\n",
            "        Applications Clocks Setting       : Not Active\n",
            "        SW Power Cap                      : Not Active\n",
            "        HW Slowdown                       : Not Active\n",
            "            HW Thermal Slowdown           : Not Active\n",
            "            HW Power Brake Slowdown       : Not Active\n",
            "        Sync Boost                        : Not Active\n",
            "        SW Thermal Slowdown               : Not Active\n",
            "        Display Clock Setting             : Not Active\n",
            "    FB Memory Usage\n",
            "        Total                             : 15109 MiB\n",
            "        Used                              : 0 MiB\n",
            "        Free                              : 15109 MiB\n",
            "    BAR1 Memory Usage\n",
            "        Total                             : 256 MiB\n",
            "        Used                              : 2 MiB\n",
            "        Free                              : 254 MiB\n",
            "    Compute Mode                          : Default\n",
            "    Utilization\n",
            "        Gpu                               : 0 %\n",
            "        Memory                            : 0 %\n",
            "        Encoder                           : 0 %\n",
            "        Decoder                           : 0 %\n",
            "    Encoder Stats\n",
            "        Active Sessions                   : 0\n",
            "        Average FPS                       : 0\n",
            "        Average Latency                   : 0\n",
            "    FBC Stats\n",
            "        Active Sessions                   : 0\n",
            "        Average FPS                       : 0\n",
            "        Average Latency                   : 0\n",
            "    Ecc Mode\n",
            "        Current                           : Enabled\n",
            "        Pending                           : Enabled\n",
            "    ECC Errors\n",
            "        Volatile\n",
            "            SRAM Correctable              : 0\n",
            "            SRAM Uncorrectable            : 0\n",
            "            DRAM Correctable              : 0\n",
            "            DRAM Uncorrectable            : 0\n",
            "        Aggregate\n",
            "            SRAM Correctable              : 0\n",
            "            SRAM Uncorrectable            : 0\n",
            "            DRAM Correctable              : 0\n",
            "            DRAM Uncorrectable            : 0\n",
            "    Retired Pages\n",
            "        Single Bit ECC                    : 0\n",
            "        Double Bit ECC                    : 0\n",
            "        Pending Page Blacklist            : No\n",
            "    Remapped Rows                         : N/A\n",
            "    Temperature\n",
            "        GPU Current Temp                  : 52 C\n",
            "        GPU Shutdown Temp                 : 96 C\n",
            "        GPU Slowdown Temp                 : 93 C\n",
            "        GPU Max Operating Temp            : 85 C\n",
            "        GPU Target Temperature            : N/A\n",
            "        Memory Current Temp               : N/A\n",
            "        Memory Max Operating Temp         : N/A\n",
            "    Power Readings\n",
            "        Power Management                  : Supported\n",
            "        Power Draw                        : 12.64 W\n",
            "        Power Limit                       : 70.00 W\n",
            "        Default Power Limit               : 70.00 W\n",
            "        Enforced Power Limit              : 70.00 W\n",
            "        Min Power Limit                   : 60.00 W\n",
            "        Max Power Limit                   : 70.00 W\n",
            "    Clocks\n",
            "        Graphics                          : 300 MHz\n",
            "        SM                                : 300 MHz\n",
            "        Memory                            : 405 MHz\n",
            "        Video                             : 540 MHz\n",
            "    Applications Clocks\n",
            "        Graphics                          : 585 MHz\n",
            "        Memory                            : 5001 MHz\n",
            "    Default Applications Clocks\n",
            "        Graphics                          : 585 MHz\n",
            "        Memory                            : 5001 MHz\n",
            "    Max Clocks\n",
            "        Graphics                          : 1590 MHz\n",
            "        SM                                : 1590 MHz\n",
            "        Memory                            : 5001 MHz\n",
            "        Video                             : 1470 MHz\n",
            "    Max Customer Boost Clocks\n",
            "        Graphics                          : 1590 MHz\n",
            "    Clock Policy\n",
            "        Auto Boost                        : N/A\n",
            "        Auto Boost Default                : N/A\n",
            "    Processes                             : None\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}